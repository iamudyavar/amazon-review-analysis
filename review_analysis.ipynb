{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e010d3f0",
   "metadata": {},
   "source": [
    "# Amazon Review Analysis (Summaries, Pros/Cons, Demographics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489ee9b8",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e161a2f1-f30d-4d1e-9efe-8e9e3cce9651",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Alien\n",
      "[nltk_data]     7\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "import torch\n",
    "import collections \n",
    "from collections import Counter\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import spacy\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c281c431",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c531421f-d8bd-45ab-b4fb-c1fe659276a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Reviews.csv', nrows = 10000)\n",
    "data = df[['Text', 'Summary']]\n",
    "data.drop_duplicates(subset=['Text'], inplace=True) # Drop duplicate rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3b6f1fe-8699-4a45-9892-653fe73f7d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_mapping = {\"ain't\": \"is not\",\"aint\": \"is not\", \"aren't\": \"are not\",\"arent\": \"are not\",\"can't\": \"cannot\",\"cant\": \"cannot\", \"'cause\": \"because\", \"cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
    "\n",
    "                           \"didn't\": \"did not\", \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
    "\n",
    "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
    "\n",
    "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
    "\n",
    "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
    "\n",
    "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
    "\n",
    "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\", 'mstake':\"mistake\",\n",
    "\n",
    "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
    "\n",
    "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
    "\n",
    "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
    "\n",
    "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
    "\n",
    "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
    "\n",
    "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
    "\n",
    "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
    "\n",
    "                           \"wasn't\": \"was not\",'wasnt':\"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
    "\n",
    "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
    "\n",
    "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
    "\n",
    "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
    "\n",
    "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
    "\n",
    "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
    "\n",
    "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "\n",
    "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
    "\n",
    "                           \"you're\": \"you are\", \"you've\": \"you have\", 'youve':\"you have\", 'goin':\"going\", '4ward':\"forward\", \"shant\":\"shall not\",'tat':\"that\", 'u':\"you\", 'v': \"we\",'b4':'before', \"sayin'\":\"saying\"\n",
    "                      }\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "def text_cleaner(text):\n",
    "    newString = text.lower()\n",
    "    newString = re.sub(r'\\([^)]*\\)', '', newString)\n",
    "    newString = re.sub('\"','', newString)\n",
    "    newString = ' '.join([word_mapping[t] if t in word_mapping else t for t in newString.split(\" \")])    \n",
    "    newString = re.sub(r\"'s\\b\",\"\",newString)\n",
    "    newString = re.sub(\"[^a-zA-Z]\", \" \", newString) \n",
    "    tokens = [w for w in newString.split() if not w in stop_words]\n",
    "    long_words=[]\n",
    "    \n",
    "    tokens = [w for w in newString.split() if not w in stop_words]\n",
    "    long_words=[]\n",
    "    for i in tokens:\n",
    "        if len(i)>=3:                  #removing short word\n",
    "            long_words.append(i) \n",
    "    text = \" \".join(long_words).strip()\n",
    "    def no_space(word, prev_word):\n",
    "        return word in set(',!\"\";.''?') and prev_word!=\" \"\n",
    "    text = text.replace('\\u202f', ' ').replace('\\xa0', ' ').lower()\n",
    "    out = [' ' + char if i > 0 and no_space(char, text[i - 1]) else char for i, char in enumerate(text)]\n",
    "    text = ''.join(out)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7ab2662-c063-496e-a69d-50ce97ae0d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['cleaned_text'] = data['Text'].apply(text_cleaner)\n",
    "data['cleaned_summary'] = data['Summary'].apply(text_cleaner)\n",
    "# this step is to remove all rows that have a blank summary\n",
    "data[\"cleaned_summary\"].replace('', np.nan, inplace=True)\n",
    "data.dropna(axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19d496ce-d6da-4216-ab69-0f02a333a61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len_text=200 \n",
    "max_len_summary=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "867517c4-2564-4928-8fac-70c13f123f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = tts(data['cleaned_text'],data['cleaned_summary'],test_size=0.1, shuffle=True, random_state=111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5856a4b0-2098-49b4-a1a1-2906198ffc17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize function \n",
    "def tokenize(lines, token='word'):\n",
    "    assert token in ('word', 'char'), 'Unknown token type: ' + token\n",
    "    return [line.split() if token == 'word' else list(line) for line in lines]\n",
    "\n",
    "# pading function\n",
    "def truncate_pad(line, num_steps, padding_token):\n",
    "    if len(line) > num_steps:\n",
    "        return line[:num_steps]  # Truncate\n",
    "    return line + [padding_token] * (num_steps - len(line))  # Pad\n",
    "\n",
    "# the vocabulary class \n",
    "class Vocab:\n",
    "    def __init__(self, tokens=[], min_freq=0, reserved_tokens=[]):\n",
    "        # Flatten a 2D list if needed\n",
    "        if tokens and isinstance(tokens[0], list):\n",
    "            tokens = [token for line in tokens for token in line]\n",
    "        # Count token frequencies\n",
    "        counter = collections.Counter(tokens)\n",
    "        self.token_freqs = sorted(counter.items(), key=lambda x: x[1],\n",
    "                                  reverse=True)\n",
    "        # The list of unique tokens\n",
    "        self.idx_to_token = list(sorted(set(['<unk>'] + reserved_tokens + [\n",
    "            token for token, freq in self.token_freqs if freq >= min_freq])))\n",
    "        self.token_to_idx = {token: idx\n",
    "                             for idx, token in enumerate(self.idx_to_token)}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.idx_to_token)\n",
    "\n",
    "    def __getitem__(self, tokens):\n",
    "        if not isinstance(tokens, (list, tuple)):\n",
    "            return self.token_to_idx.get(tokens, self.unk)\n",
    "        return [self.__getitem__(token) for token in tokens]\n",
    "\n",
    "    def to_tokens(self, indices):\n",
    "        if hasattr(indices, '__len__') and len(indices) > 1:\n",
    "            return [self.idx_to_token[int(index)] for index in indices]\n",
    "        return self.idx_to_token[indices]\n",
    "\n",
    "    def unk(self):  # Index for the unknown token\n",
    "        return self.token_to_idx['<unk>']\n",
    "# tokenize\n",
    "src_tokens = tokenize(x_train)\n",
    "tgt_tokens = tokenize(y_train)\n",
    "# build vocabulary on dataset\n",
    "src_vocab = Vocab(src_tokens, reserved_tokens=['<pad>', '<bos>', '<eos>'])\n",
    "tgt_vocab = Vocab(tgt_tokens, reserved_tokens=['<pad>', '<bos>', '<eos>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "030e5180-8da1-4c4e-825e-fdd2217c0fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fn to add eos and padding and also determine valid length of each data sample\n",
    "def build_array_sum(lines, vocab, num_steps):\n",
    "    lines = [vocab[l] for l in lines]\n",
    "    lines = [l + [vocab['<eos>']] for l in lines]\n",
    "    array = torch.tensor([truncate_pad(l, num_steps, vocab['<pad>']) for l in lines])\n",
    "    valid_len = (array != vocab['<pad>']).type(torch.int32).sum(1)\n",
    "    return array, valid_len\n",
    "\n",
    "src_array, src_valid_len = build_array_sum(src_tokens, src_vocab, max_len_text)\n",
    "tgt_array, tgt_valid_len = build_array_sum(tgt_tokens, tgt_vocab, max_len_summary)\n",
    "data_arrays = (src_array, src_valid_len, tgt_array, tgt_valid_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "135421a4-9371-4d16-95c7-07428b0634a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the tensor dataset object \n",
    "def load_array(data_arrays, batch_size, is_train=True):\n",
    "    dataset = torch.utils.data.TensorDataset(*data_arrays)\n",
    "    return torch.utils.data.DataLoader(dataset, batch_size, shuffle=is_train)\n",
    "batch_size = 64\n",
    "data_iter = load_array(data_arrays, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869b5d62",
   "metadata": {},
   "source": [
    "## Transformer Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa585d10-7a5c-4ebe-9be5-b60784109879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The main class \n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, key_size, query_size, value_size, num_hiddens, num_heads, dropout, bias=False, **kwargs):\n",
    "        super(MultiHeadAttention, self).__init__(**kwargs)\n",
    "        self.num_heads = num_heads\n",
    "        self.attention = DotProductAttention(dropout)\n",
    "        self.w_q = nn.Linear(query_size, num_hiddens, bias=bias)\n",
    "        self.w_k = nn.Linear(key_size, num_hiddens, bias=bias)\n",
    "        self.w_v = nn.Linear(value_size, num_hiddens, bias=bias)\n",
    "        self.w_o = nn.Linear(num_hiddens, num_hiddens, bias=bias)\n",
    "    def forward(self, queries, keys, values, valid_lens):\n",
    "        queries = transpose_qkv(self.w_q(queries), self.num_heads)\n",
    "        keys = transpose_qkv(self.w_k(keys), self.num_heads)\n",
    "        values = transpose_qkv(self.w_v(values), self.num_heads)\n",
    "        if valid_lens is not None:\n",
    "            valid_lens = torch.repeat_interleave(valid_lens, repeats = self.num_heads, dim=0)\n",
    "        output = self.attention(queries, keys, values, valid_lens)\n",
    "        output_concat = transpose_output(output, self.num_heads)\n",
    "        return self.w_o(output_concat)\n",
    "\n",
    "# Function to transpose the linearly transformed query key and values \n",
    "def transpose_qkv(X, num_heads):\n",
    "    X = X.reshape(X.shape[0], X.shape[1], num_heads, -1)\n",
    "    X = X.permute(0, 2, 1, 3)\n",
    "    return X.reshape(-1, X.shape[2], X.shape[3])\n",
    "\n",
    "# For output formatting \n",
    "def transpose_output(X, num_heads):\n",
    "    X = X.reshape(-1, num_heads, X.shape[1], X.shape[2])\n",
    "    X = X.permute(0, 2, 1, 3)\n",
    "    return X.reshape(X.shape[0], X.shape[1], -1)\n",
    "\n",
    "# The dot product attention scoring function \n",
    "class DotProductAttention(nn.Module):\n",
    "    def __init__(self, dropout, **kwargs):\n",
    "        super(DotProductAttention, self).__init__(**kwargs)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    def forward(self, queries, keys, values, valid_lens=None):\n",
    "        d = queries.shape[-1]\n",
    "        scores = torch.bmm(queries, keys.transpose(1, 2))/math.sqrt(d)\n",
    "        self.attention_weights = masked_softmax(scores, valid_lens)\n",
    "        return torch.bmm(self.dropout(self.attention_weights), values)\n",
    "# Here masking is used so that irrelevant padding tokens are not considered\n",
    "# while calculations\n",
    "\n",
    "def sequence_mask(X, valid_len, value=0):\n",
    "    maxlen = X.size(1)\n",
    "    mask = torch.arange((maxlen), dtype=torch.float32)[None, :] < valid_len[:, None]    #device=X.device\n",
    "    X[~mask] = value\n",
    "    return X\n",
    "# the irrelevant tokens are given a very small negative value which gets\n",
    "# ignored in the subsequent calculations\n",
    "def masked_softmax(X, valid_lens):\n",
    "    if valid_lens is None:\n",
    "        return nn.functional.softmax(X, dim=-1)\n",
    "    else:\n",
    "        shape = X.shape\n",
    "        if valid_lens.dim() == 1:\n",
    "            valid_lens = torch.repeat_interleave(valid_lens, shape[1])\n",
    "        else:\n",
    "            valid_lens = valid_lens.reshape(-1) \n",
    "        X = sequence_mask(X.reshape(-1, shape[-1]), valid_lens, value=-1e6)\n",
    "        return nn.functional.softmax(X.reshape(shape), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45f5a1e5-c401-4b98-bcda-16d606b3367a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionWiseFFN(nn.Module):\n",
    "    def __init__(self, ffn_num_input, ffn_num_hiddens, ffn_num_output, **kwargs):\n",
    "        super(PositionWiseFFN, self).__init__(**kwargs)\n",
    "        self.dense1 = nn.Linear(ffn_num_input, ffn_num_hiddens)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dense2 = nn.Linear(ffn_num_hiddens, ffn_num_output)\n",
    "    def forward(self, X):\n",
    "        return self.dense2(self.relu(self.dense1(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "473ab623-7b11-4e94-aeed-48c10072a37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, num_hiddens, dropout, max_len=1000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.P = torch.zeros((1, max_len, num_hiddens))\n",
    "        X = torch.arange(max_len, dtype=torch.float32).reshape(-1, 1)/torch.pow(10000,torch.arange(0, num_hiddens,2, dtype=torch.float32)/num_hiddens)\n",
    "        self.P[:,:, 0::2] = torch.sin(X)\n",
    "        self.P[:, :, 1::2] = torch.cos(X)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        X = X + self.P[:, :X.shape[1], :].to(X.device)\n",
    "        return self.dropout(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0cb352f6-e1c4-43a3-8940-6335008aae1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddNorm(nn.Module):\n",
    "    def __init__(self, normalized_shape, dropout):\n",
    "        super(AddNorm, self).__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.ln = nn.LayerNorm(normalized_shape)\n",
    "\n",
    "    def forward(self, X, Y):\n",
    "        return self.ln(X + self.dropout(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a044a5aa-bf76-41f3-8e46-6f754ceb8bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class for the block structure within \n",
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self, key_size, query_size, value_size, num_hiddens, norm_shape, ffn_num_input, \n",
    "                 ffn_num_hiddens, num_heads, dropout, use_bias=False, **kwargs):\n",
    "        super(EncoderBlock, self).__init__(**kwargs)\n",
    "        self.attention = MultiHeadAttention(key_size, query_size, value_size, num_hiddens,num_heads, dropout, use_bias)\n",
    "        self.addnorm1 = AddNorm(norm_shape, dropout)\n",
    "        self.ffn = PositionWiseFFN(ffn_num_input, ffn_num_hiddens, num_hiddens)\n",
    "        self.addnorm2 = AddNorm(norm_shape, dropout)\n",
    "        \n",
    "    def forward(self, X, valid_lens):\n",
    "        Y = self.addnorm1(X, self.attention(X, X, X, valid_lens))\n",
    "        return self.addnorm2(Y, self.ffn(Y))\n",
    "\n",
    "# the main encoder class\n",
    "class TransformerEncoder(nn.Module):\n",
    "    def __init__(self, vocab_size, key_size, query_size, value_size, num_hiddens, norm_shape, ffn_num_input, ffn_num_hiddens, num_heads, num_layers, dropout, use_bias=False, **kwargs):\n",
    "        super(TransformerEncoder, self).__init__(**kwargs)\n",
    "        self.num_hiddens = num_hiddens\n",
    "        self.embedding = nn.Embedding(vocab_size, num_hiddens)\n",
    "        self.pos_encoding = PositionalEncoding(num_hiddens, dropout)\n",
    "        self.blks = nn.Sequential()\n",
    "        for i in range(num_layers):\n",
    "            self.blks.add_module(\"block\"+str(i),EncoderBlock(key_size, query_size, value_size, num_hiddens, norm_shape, ffn_num_input, ffn_num_hiddens, num_heads, dropout, use_bias))\n",
    "    \n",
    "    def forward(self, X, valid_lens, *args):\n",
    "        X = self.pos_encoding(self.embedding(X)*math.sqrt(self.num_hiddens))\n",
    "        self.attention_weights = [None]*len(self.blks)\n",
    "        for i, blk in enumerate(self.blks):\n",
    "            X = blk(X, valid_lens)\n",
    "            self.attention_weights[i] = blk.attention.attention.attention_weights\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b4fd9c60-31a5-4069-a83a-8fcb920e63c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, key_size, query_size, value_size, num_hiddens, norm_shape,\n",
    "                 ffn_num_input, ffn_num_hiddens, num_heads, dropout, i, **kwargs):\n",
    "        super(DecoderBlock, self).__init__(**kwargs)\n",
    "        self.i = i\n",
    "        self.attention1 = MultiHeadAttention(key_size, query_size, value_size, num_hiddens, num_heads, dropout)\n",
    "        self.addnorm1 = AddNorm(norm_shape, dropout)\n",
    "        self.attention2 = MultiHeadAttention(key_size, query_size, value_size, num_hiddens, num_heads, dropout)\n",
    "        self.addnorm2 = AddNorm(norm_shape, dropout)\n",
    "        self.ffn = PositionWiseFFN(ffn_num_input, ffn_num_hiddens, num_hiddens)\n",
    "        self.addnorm3 = AddNorm(norm_shape, dropout)\n",
    "        \n",
    "    def forward(self, X, state):\n",
    "        enc_outputs, enc_valid_lens = state[0], state[1]\n",
    "        if state[2][self.i] is None: # true when training the model\n",
    "            key_values = X\n",
    "        else:                        # while decoding state[2][self.i] is decoded output of the ith block till the present time-step\n",
    "            key_values = torch.cat((state[2][self.i], X), axis=1)\n",
    "        state[2][self.i] = key_values\n",
    "        if self.training:\n",
    "            batch_size, num_steps, _ = X.shape\n",
    "            dec_valid_lens = torch.arange(1, num_steps+1, device = X.device).repeat(batch_size, 1)\n",
    "        else:\n",
    "            dec_valid_lens = None\n",
    "        X2 = self.attention1(X, key_values, key_values, dec_valid_lens)\n",
    "        Y = self.addnorm1(X, X2)\n",
    "        Y2 = self.attention2(Y, enc_outputs, enc_outputs, enc_valid_lens)\n",
    "        Z = self.addnorm2(Y, Y2)\n",
    "        return self.addnorm3(Z, self.ffn(Z)), state\n",
    "\n",
    "# The main decoder class \n",
    "class TransformerDecoder(nn.Module):\n",
    "    def __init__(self, vocab_size, key_size, query_size, value_size, num_hiddens,\n",
    "                 norm_shape, ffn_num_input, ffn_num_hiddens, num_heads, num_layers, dropout, **kwargs):\n",
    "        super(TransformerDecoder, self).__init__(**kwargs)\n",
    "        self.num_hiddens = num_hiddens\n",
    "        self.num_layers = num_layers\n",
    "        self.embedding = nn.Embedding(vocab_size, num_hiddens)\n",
    "        self.pos_encoding = PositionalEncoding(num_hiddens, dropout)\n",
    "        self.blks = nn.Sequential()\n",
    "        for i in range(num_layers):\n",
    "            self.blks.add_module(\"block\"+str(i), \n",
    "                                DecoderBlock(key_size, query_size, value_size,\n",
    "                                             num_hiddens, norm_shape, ffn_num_input, ffn_num_hiddens, num_heads, dropout, i))\n",
    "            self.dense = nn.Linear(num_hiddens, vocab_size)\n",
    "    \n",
    "    def init_state(self, enc_outputs, enc_valid_lens, *args):\n",
    "        return [enc_outputs, enc_valid_lens, [None]*self.num_layers]\n",
    "    \n",
    "    def forward(self, X, state):\n",
    "        X = self.pos_encoding(self.embedding(X)*math.sqrt(self.num_hiddens))\n",
    "        self._attention_weights = [[None]*len(self.blks) for _ in range(2)]\n",
    "        for i, blk in enumerate(self.blks):\n",
    "            X, state = blk(X, state)\n",
    "            self._attention_weights[0][i] = blk.attention1.attention.attention_weights\n",
    "            self._attention_weights[1][i] = blk.attention2.attention.attention_weights\n",
    "        return self.dense(X), state\n",
    "    \n",
    "    def attention_weights(self):\n",
    "        return self._attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "421064ba-59c3-41c8-9672-d7bc7a5a0f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, enc_X, dec_X, *args):\n",
    "        enc_all_outputs = self.encoder(enc_X, *args)\n",
    "        dec_state = self.decoder.init_state(enc_all_outputs, *args)\n",
    "        # Return decoder output only\n",
    "        return self.decoder(dec_X, dec_state)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0d77eeee-7fc0-488d-a324-96a68574c605",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device(i=0):\n",
    "    if torch.cuda.device_count() >= i+1:\n",
    "        return torch.device(f'cuda:{i}')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "device = get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f4cf2ea4-5beb-4eb7-8ff8-e73b81bddf6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(layers):\n",
    "    if type(layers) == nn.Linear:\n",
    "        nn.init.xavier_uniform_(layers.weight)\n",
    "    if (type(layers) == nn.LSTM or type(layers) == nn.GRU):\n",
    "        for param in layers._flat_weights_names:\n",
    "            if \"weight\" in param:\n",
    "                nn.init.xavier_uniform_(layers._parameters[param])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ceb8edff-efb0-41f3-81e7-e5ede1634368",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transformer(\n",
       "  (encoder): TransformerEncoder(\n",
       "    (embedding): Embedding(16455, 32)\n",
       "    (pos_encoding): PositionalEncoding(\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (blks): Sequential(\n",
       "      (block0): EncoderBlock(\n",
       "        (attention): MultiHeadAttention(\n",
       "          (attention): DotProductAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (w_q): Linear(in_features=32, out_features=32, bias=False)\n",
       "          (w_k): Linear(in_features=32, out_features=32, bias=False)\n",
       "          (w_v): Linear(in_features=32, out_features=32, bias=False)\n",
       "          (w_o): Linear(in_features=32, out_features=32, bias=False)\n",
       "        )\n",
       "        (addnorm1): AddNorm(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ffn): PositionWiseFFN(\n",
       "          (dense1): Linear(in_features=32, out_features=64, bias=True)\n",
       "          (relu): ReLU()\n",
       "          (dense2): Linear(in_features=64, out_features=32, bias=True)\n",
       "        )\n",
       "        (addnorm2): AddNorm(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (block1): EncoderBlock(\n",
       "        (attention): MultiHeadAttention(\n",
       "          (attention): DotProductAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (w_q): Linear(in_features=32, out_features=32, bias=False)\n",
       "          (w_k): Linear(in_features=32, out_features=32, bias=False)\n",
       "          (w_v): Linear(in_features=32, out_features=32, bias=False)\n",
       "          (w_o): Linear(in_features=32, out_features=32, bias=False)\n",
       "        )\n",
       "        (addnorm1): AddNorm(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ffn): PositionWiseFFN(\n",
       "          (dense1): Linear(in_features=32, out_features=64, bias=True)\n",
       "          (relu): ReLU()\n",
       "          (dense2): Linear(in_features=64, out_features=32, bias=True)\n",
       "        )\n",
       "        (addnorm2): AddNorm(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): TransformerDecoder(\n",
       "    (embedding): Embedding(4015, 32)\n",
       "    (pos_encoding): PositionalEncoding(\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (blks): Sequential(\n",
       "      (block0): DecoderBlock(\n",
       "        (attention1): MultiHeadAttention(\n",
       "          (attention): DotProductAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (w_q): Linear(in_features=32, out_features=32, bias=False)\n",
       "          (w_k): Linear(in_features=32, out_features=32, bias=False)\n",
       "          (w_v): Linear(in_features=32, out_features=32, bias=False)\n",
       "          (w_o): Linear(in_features=32, out_features=32, bias=False)\n",
       "        )\n",
       "        (addnorm1): AddNorm(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (attention2): MultiHeadAttention(\n",
       "          (attention): DotProductAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (w_q): Linear(in_features=32, out_features=32, bias=False)\n",
       "          (w_k): Linear(in_features=32, out_features=32, bias=False)\n",
       "          (w_v): Linear(in_features=32, out_features=32, bias=False)\n",
       "          (w_o): Linear(in_features=32, out_features=32, bias=False)\n",
       "        )\n",
       "        (addnorm2): AddNorm(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ffn): PositionWiseFFN(\n",
       "          (dense1): Linear(in_features=32, out_features=64, bias=True)\n",
       "          (relu): ReLU()\n",
       "          (dense2): Linear(in_features=64, out_features=32, bias=True)\n",
       "        )\n",
       "        (addnorm3): AddNorm(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (block1): DecoderBlock(\n",
       "        (attention1): MultiHeadAttention(\n",
       "          (attention): DotProductAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (w_q): Linear(in_features=32, out_features=32, bias=False)\n",
       "          (w_k): Linear(in_features=32, out_features=32, bias=False)\n",
       "          (w_v): Linear(in_features=32, out_features=32, bias=False)\n",
       "          (w_o): Linear(in_features=32, out_features=32, bias=False)\n",
       "        )\n",
       "        (addnorm1): AddNorm(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (attention2): MultiHeadAttention(\n",
       "          (attention): DotProductAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (w_q): Linear(in_features=32, out_features=32, bias=False)\n",
       "          (w_k): Linear(in_features=32, out_features=32, bias=False)\n",
       "          (w_v): Linear(in_features=32, out_features=32, bias=False)\n",
       "          (w_o): Linear(in_features=32, out_features=32, bias=False)\n",
       "        )\n",
       "        (addnorm2): AddNorm(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ffn): PositionWiseFFN(\n",
       "          (dense1): Linear(in_features=32, out_features=64, bias=True)\n",
       "          (relu): ReLU()\n",
       "          (dense2): Linear(in_features=64, out_features=32, bias=True)\n",
       "        )\n",
       "        (addnorm3): AddNorm(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (dense): Linear(in_features=32, out_features=4015, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_hiddens, num_layers, dropout, num_steps = 32, 2, 0.1, 10\n",
    "ffn_num_input, ffn_num_hiddens, num_heads = 32, 64, 4\n",
    "key_size, query_size, value_size = 32, 32, 32\n",
    "norm_shape = [32]\n",
    "encoder = TransformerEncoder(len(src_vocab), key_size, query_size, value_size, num_hiddens,norm_shape, ffn_num_input, ffn_num_hiddens, num_heads,num_layers, dropout)\n",
    "decoder = TransformerDecoder(len(tgt_vocab), key_size, query_size, value_size, num_hiddens,norm_shape, ffn_num_input, ffn_num_hiddens, num_heads,num_layers, dropout)\n",
    "net = Transformer(encoder, decoder)\n",
    "net.apply(initialize_weights)  # initialize the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fecac768-09dc-448a-9ca8-6ed4ca4ddf88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_clipping(net, theta):\n",
    "    if isinstance(net, nn.Module):\n",
    "        params = [p for p in net.parameters() if p.requires_grad]\n",
    "    else:\n",
    "        params = net.params\n",
    "    norm = torch.sqrt(sum(torch.sum((p.grad ** 2)) for p in params))\n",
    "    if norm > theta:\n",
    "        for param in params:\n",
    "            param.grad[:] *= theta / norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bddf9b64-7f1f-4f7c-9f99-628c6ab4a4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Accumulator:\n",
    "    def __init__(self, n):\n",
    "        self.data = [0.0] * n\n",
    "\n",
    "    def add(self, *args):\n",
    "        self.data = [a + float(b) for a, b in zip(self.data, args)]\n",
    "\n",
    "    def reset(self):\n",
    "        self.data = [0.0] * len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ebaa385b-59cd-42d2-b2e5-30f2f9a31ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedSoftmaxCELoss(nn.CrossEntropyLoss):\n",
    "    # `pred` shape: (`batch_size`, `num_steps`, `vocab_size`)\n",
    "    # `label` shape: (`batch_size`, `num_steps`)\n",
    "    # `valid_len` shape: (`batch_size`,)\n",
    "    def forward(self, pred, label, valid_len):\n",
    "        weights = torch.ones_like(label)\n",
    "        weights = sequence_mask(weights, valid_len)\n",
    "        self.reduction='none'\n",
    "        unweighted_loss = super(MaskedSoftmaxCELoss, self).forward(pred.permute(0, 2, 1), label)\n",
    "        weighted_loss = (unweighted_loss * weights).mean(dim=1)\n",
    "        return weighted_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a66e91",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2370c67d-c73a-4bee-bfae-72efdc79bbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_seq2seq(net, data_iter, lr, num_epochs, tgt_vocab, device):    \n",
    "    net.to(device)\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "    loss = MaskedSoftmaxCELoss()\n",
    "    net.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        metric = Accumulator(2)  # Sum of training loss, no. of tokens\n",
    "        for batch in data_iter:\n",
    "            optimizer.zero_grad()\n",
    "            X, X_valid_len, Y, Y_valid_len = [x.to(device) for x in batch]\n",
    "            bos = torch.tensor([tgt_vocab['<bos>']] * Y.shape[0],device=device).reshape(-1, 1)\n",
    "            dec_input = torch.cat([bos, Y[:, :-1]], 1)  # Teacher forcing\n",
    "            Y_hat = net(X, dec_input, X_valid_len)\n",
    "            l = loss(Y_hat, Y, Y_valid_len)\n",
    "            l.sum().backward()  # Make the loss scalar for `backward`\n",
    "            grad_clipping(net, 1)\n",
    "            num_tokens = Y_valid_len.sum()\n",
    "            optimizer.step()\n",
    "            with torch.no_grad():\n",
    "                metric.add(l.sum(), num_tokens)\n",
    "        print(f\"Done with epoch number: {epoch+1}\") # optional step\n",
    "    print(f'loss {metric[0] / metric[1]:.3f} on {str(device)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "99a17ae5-ab76-4e50-a4da-490a9e91345e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.005\n",
    "num_epochs = 100\n",
    "\n",
    "# Uncomment the line below to train the model\n",
    "# train_seq2seq(net, data_iter, lr, num_epochs, tgt_vocab, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "28da64fe-8d8b-41d9-a297-ec574fd77bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_seq2seq(net, src_sentence, src_vocab, tgt_vocab, num_steps,device, save_attention_weights=False):\n",
    "    # Set `net` to eval mode for inference\n",
    "    net.eval()\n",
    "    src_tokens = src_vocab[src_sentence.lower().split()] + [src_vocab['<eos>']]\n",
    "    src_tokens = [src_vocab[token] if token in src_vocab.token_to_idx else src_vocab['<unk>'] for token in src_sentence.lower().split()]\n",
    "    enc_valid_len = torch.tensor([len(src_tokens)], device=device)\n",
    "    src_tokens = truncate_pad(src_tokens, num_steps, src_vocab['<pad>'])\n",
    "    # Unsqueeze adds another dimension that works as the the batch axis here\n",
    "    enc_X = torch.unsqueeze(torch.tensor(src_tokens, dtype=torch.long, device=device), dim=0)\n",
    "    enc_outputs = net.encoder(enc_X, enc_valid_len)\n",
    "    dec_state = net.decoder.init_state(enc_outputs, enc_valid_len)\n",
    "    # Add the batch axis to the decoder now\n",
    "    dec_X = torch.unsqueeze(torch.tensor([tgt_vocab['<bos>']], dtype=torch.long, device=device), dim=0)\n",
    "    output_seq, attention_weight_seq = [], []\n",
    "    for _ in range(num_steps):\n",
    "        Y = net.decoder(dec_X, dec_state)[0]\n",
    "        # We use the token with the highest prediction likelihood as the input\n",
    "        # of the decoder at the next time step\n",
    "        dec_X = Y.argmax(dim=2)\n",
    "        pred = dec_X.squeeze(dim=0).type(torch.int32).item()\n",
    "        # Save attention weights\n",
    "        if save_attention_weights:\n",
    "            attention_weight_seq.append(net.decoder.attention_weights)\n",
    "            # Once the end-of-sequence token is predicted, the generation of the output sequence is complete\n",
    "        if pred == tgt_vocab['<eos>']:\n",
    "                break\n",
    "        output_seq.append(pred)\n",
    "    if len(output_seq)<2:\n",
    "        \n",
    "        if len(output_seq)==1: \n",
    "            return ''.join(tgt_vocab.to_tokens(output_seq[0])), attention_weight_seq   \n",
    "        else:\n",
    "            \n",
    "            return \"No output!\", attention_weight_seq\n",
    "    else:\n",
    "        return ' '.join(tgt_vocab.to_tokens(output_seq)), attention_weight_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf27ee26",
   "metadata": {},
   "source": [
    "## Applying the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f16757bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transformer(\n",
       "  (encoder): TransformerEncoder(\n",
       "    (embedding): Embedding(16455, 32)\n",
       "    (pos_encoding): PositionalEncoding(\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (blks): Sequential(\n",
       "      (block0): EncoderBlock(\n",
       "        (attention): MultiHeadAttention(\n",
       "          (attention): DotProductAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (w_q): Linear(in_features=32, out_features=32, bias=False)\n",
       "          (w_k): Linear(in_features=32, out_features=32, bias=False)\n",
       "          (w_v): Linear(in_features=32, out_features=32, bias=False)\n",
       "          (w_o): Linear(in_features=32, out_features=32, bias=False)\n",
       "        )\n",
       "        (addnorm1): AddNorm(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ffn): PositionWiseFFN(\n",
       "          (dense1): Linear(in_features=32, out_features=64, bias=True)\n",
       "          (relu): ReLU()\n",
       "          (dense2): Linear(in_features=64, out_features=32, bias=True)\n",
       "        )\n",
       "        (addnorm2): AddNorm(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (block1): EncoderBlock(\n",
       "        (attention): MultiHeadAttention(\n",
       "          (attention): DotProductAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (w_q): Linear(in_features=32, out_features=32, bias=False)\n",
       "          (w_k): Linear(in_features=32, out_features=32, bias=False)\n",
       "          (w_v): Linear(in_features=32, out_features=32, bias=False)\n",
       "          (w_o): Linear(in_features=32, out_features=32, bias=False)\n",
       "        )\n",
       "        (addnorm1): AddNorm(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ffn): PositionWiseFFN(\n",
       "          (dense1): Linear(in_features=32, out_features=64, bias=True)\n",
       "          (relu): ReLU()\n",
       "          (dense2): Linear(in_features=64, out_features=32, bias=True)\n",
       "        )\n",
       "        (addnorm2): AddNorm(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): TransformerDecoder(\n",
       "    (embedding): Embedding(4015, 32)\n",
       "    (pos_encoding): PositionalEncoding(\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (blks): Sequential(\n",
       "      (block0): DecoderBlock(\n",
       "        (attention1): MultiHeadAttention(\n",
       "          (attention): DotProductAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (w_q): Linear(in_features=32, out_features=32, bias=False)\n",
       "          (w_k): Linear(in_features=32, out_features=32, bias=False)\n",
       "          (w_v): Linear(in_features=32, out_features=32, bias=False)\n",
       "          (w_o): Linear(in_features=32, out_features=32, bias=False)\n",
       "        )\n",
       "        (addnorm1): AddNorm(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (attention2): MultiHeadAttention(\n",
       "          (attention): DotProductAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (w_q): Linear(in_features=32, out_features=32, bias=False)\n",
       "          (w_k): Linear(in_features=32, out_features=32, bias=False)\n",
       "          (w_v): Linear(in_features=32, out_features=32, bias=False)\n",
       "          (w_o): Linear(in_features=32, out_features=32, bias=False)\n",
       "        )\n",
       "        (addnorm2): AddNorm(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ffn): PositionWiseFFN(\n",
       "          (dense1): Linear(in_features=32, out_features=64, bias=True)\n",
       "          (relu): ReLU()\n",
       "          (dense2): Linear(in_features=64, out_features=32, bias=True)\n",
       "        )\n",
       "        (addnorm3): AddNorm(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (block1): DecoderBlock(\n",
       "        (attention1): MultiHeadAttention(\n",
       "          (attention): DotProductAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (w_q): Linear(in_features=32, out_features=32, bias=False)\n",
       "          (w_k): Linear(in_features=32, out_features=32, bias=False)\n",
       "          (w_v): Linear(in_features=32, out_features=32, bias=False)\n",
       "          (w_o): Linear(in_features=32, out_features=32, bias=False)\n",
       "        )\n",
       "        (addnorm1): AddNorm(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (attention2): MultiHeadAttention(\n",
       "          (attention): DotProductAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (w_q): Linear(in_features=32, out_features=32, bias=False)\n",
       "          (w_k): Linear(in_features=32, out_features=32, bias=False)\n",
       "          (w_v): Linear(in_features=32, out_features=32, bias=False)\n",
       "          (w_o): Linear(in_features=32, out_features=32, bias=False)\n",
       "        )\n",
       "        (addnorm2): AddNorm(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (ffn): PositionWiseFFN(\n",
       "          (dense1): Linear(in_features=32, out_features=64, bias=True)\n",
       "          (relu): ReLU()\n",
       "          (dense2): Linear(in_features=64, out_features=32, bias=True)\n",
       "        )\n",
       "        (addnorm3): AddNorm(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (dense): Linear(in_features=32, out_features=4015, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = Transformer(encoder, decoder)\n",
    "net.load_state_dict(torch.load(\"transformer_summarizer.pth\", map_location=device))\n",
    "net.to(device)\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "57c1eaa6-252d-401e-9bdf-1cdcf1830473",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_product_reviews(product_id, df, net, src_vocab, tgt_vocab, num_steps, device):\n",
    "    # Filter reviews for the given product ID\n",
    "    reviews = df[df['ProductId'] == product_id]['Text'].dropna().tolist()\n",
    "    if not reviews:\n",
    "        return \"No reviews found for this product ID.\"\n",
    "    \n",
    "    # Clean and concatenate all reviews into one string\n",
    "    cleaned_reviews = [text_cleaner(review) for review in reviews]\n",
    "    full_text = ' '.join(cleaned_reviews)\n",
    "    \n",
    "    # Summarize\n",
    "    summary, _ = predict_seq2seq(net, full_text, src_vocab, tgt_vocab, num_steps, device)\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fdef25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This product is popular among both males and females.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAoAAAAH4CAYAAADaVFwSAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABg60lEQVR4nO3dd3hT9f4H8HeSJmm6B6V0QFv23qiALMHBcqDilqGiONGrXnFc5XrVn+LALaKCC0EEXAgqU5bIhgJtKXTQ0tKdrrTNOL8/aiOhLXSk/eac8349Tx9ocnryadIk73ynRpIkCURERESkGlrRBRARERFR62IAJCIiIlIZBkAiIiIilWEAJCIiIlIZBkAiIiIilWEAJCIiIlIZBkAiIiIilWEAJCIiIlIZBkAiIiIilWEAJI8RGxuL6dOniy6jXhqNBi+88EKL387mzZuh0WiwefNm52WjR49G7969W/y2ASA1NRUajQZLlixplds715dffonu3btDr9cjKChISA2tRfR9TUTqxQCoQikpKXjwwQfRtWtX+Pj4wMfHBz179sQDDzyAQ4cOiS6vVcTGxkKj0UCj0UCr1SIoKAh9+vTBrFmzsGvXLrfdztKlS7FgwQK3nc+dPLG2hIQETJ8+HZ06dcKiRYvw8ccft+jtvfDCC86/A41G43wuPPvssyguLm7R224tL7/8Mr7//vsGHVsTSF9//XXnZTUfSGq+jEYjwsPDMXr0aLz88svIzc1t1LnP/goICED//v3x3nvvwW631/qZY8eO4aqrroKfnx9CQkJwxx131Hl7DocDr732GuLi4uDt7Y2+ffvim2++qXXcokWLMGrUKISHh8NoNCIuLg4zZsxAamqq85g333wTGo0G69evr/d3WbRoETQaDX788Ufk5OQgJCQEl112Wa3jrFYr+vTpg9jYWJSVlQEAlixZUut+qPl66qmnnD8bGxuLSZMm1Trnl19+CZ1Oh6uuugoVFRW1rj9x4gS8vb2h0WiwZ8+een8HALjnnnug0WjqvB1SPi/RBVDr+vnnn3HTTTfBy8sLt912G/r16wetVouEhASsWrUKH374IVJSUhATEyO61BbXv39//Otf/wIAlJSU4NixY1ixYgUWLVqERx99FG+++abL8RaLBV5ejXvKLF26FPHx8ZgzZ06Df2bkyJGwWCwwGAyNuq3Gqq+2mJgYWCwW6PX6Fr39umzevBkOhwNvv/02Onfu3Gq3++GHH8LPzw+lpaX47bff8NJLL2Hjxo3Yvn07NBpNq9XREl5++WXccMMNuPbaa5t1nocffhhDhgyB3W5Hbm4uduzYgeeffx5vvvkmvv322zoDUF1uueUWTJgwAQBgNpvxyy+/4KGHHkJaWhrmz5/vPC4jIwMjR45EYGAgXn75ZZSWluL111/H4cOH8ddff7k8P5555hn83//9H+655x4MGTIEP/zwA2699VZoNBrcfPPNzuP279+PuLg4XH311QgODkZKSgoWLVqEn3/+GQcPHkRkZCRuvvlmPPHEE1i6dCnGjRtX5++wdOlShIaGYvz48dDr9Xj11Vcxa9YsfP7555g2bZrzuDfeeAPx8fH46aef4Ovr63KO//73v4iLi3O57EKt/F9//TWmT5+OcePG4fvvv4e3t3etYx599FF4eXmhsrLyvOfas2cPlixZUuc5SCUkUo3k5GTJ19dX6tGjh3T69Ola11utVuntt9+W0tPTBVQnSTExMdK0adPcci6r1SpVVlae97YmTpxY6/Ly8nLp2muvlQBIH3zwQbPrmDhxohQTE9OgYy0Wi2S32+u8btSoUVKvXr2aXc/ZGlNba5k3b54EQMrNzXXbOcvKyuq97vnnn6/z9qZMmSIBkHbs2NGk8zZUSkqKBEBavHhxs89VH19f3wY/r2rqmT9/vvOyTZs2SQCkFStW1Dr+wIEDUtu2baWgoKA6X1MudG5JkiSHwyENGTJEioyMdLl89uzZkslkktLS0pyX/f777xIAaeHChc7LMjIyJL1eLz3wwAMu5xwxYoQUHR0t2Wy289a1Z88eCYD0yiuvOC8bO3asFBgYKFVUVNQ6PiMjQ9JqtdJ9993ncnuXXnqp1KZNGykvL0+SJEk6efKkZDKZpClTprj8/OLFiyUA0u7du89b17mvUd98842k0+mkcePGSRaLpc6fWbdunWQwGKRnn332vLfhcDikoUOHSjNnzqz3tZCUj13AKvLaa6+hrKwMixcvRkRERK3rvby88PDDD6N9+/YulyckJOCGG25ASEgIvL29MXjwYPz4448ux9R0a2zfvh2PPfYYwsLC4Ovri+uuu65Wl40kSfjf//6H6Oho+Pj4YMyYMThy5EidNRcVFWHOnDlo3749jEYjOnfujFdffRUOh8N5zNndVgsWLECnTp1gNBpx9OjRRt9HJpMJX375JUJCQvDSSy9BkiTndeeOASwpKcGcOXMQGxsLo9GItm3b4vLLL8e+ffsAVI/bW7NmDdLS0pxdPLGxsQD+6VZbtmwZnn32WURFRcHHxwfFxcV1jgGssXfvXgwbNgwmkwlxcXH46KOPXK6veRzO7tI6+/Zqznm+2uobl7Zx40aMGDECvr6+CAoKwjXXXINjx465HFPTpZqcnIzp06cjKCgIgYGBmDFjBsrLy89738fGxuL5558HAISFhdW6vz/44AP06tULRqMRkZGReOCBB1BUVORyjpqxknv37sXIkSPh4+ODp59++ry3W5ea1qyUlJQLnjcnJwd33XUXwsPD4e3tjX79+uHzzz+vdc6ioiJMnz4dgYGBCAoKwrRp02rVX3Nbo0ePrnX59OnTnY9RjZrW0j59+sDb2xthYWG46qqrnF1/Go0GZWVl+Pzzz52PszvH2fbr1w8LFixAUVER3nvvvSadQ6PRIDw8vFbr+sqVKzFp0iR06NDBedm4cePQtWtXfPvtt87LfvjhB1itVtx///0u55w9ezYyMjKwc+fO895+zX169mNx++23w2w2Y82aNbWOX7ZsGRwOB2677TaX2/voo49gNpvx+OOPAwDuv/9+eHl54Z133rnwnXAB3377LW6//XaMHj0aP/74Y52tdlarFY888ggeeeQRdOrU6bzn+/LLLxEfH4+XXnqp2bWRfLELWEV+/vlndO7cGRdffHGDf+bIkSMYPnw4oqKi8NRTT8HX1xfffvstrr32WqxcuRLXXXedy/EPPfQQgoOD8fzzzyM1NRULFizAgw8+iOXLlzuP+c9//oP//e9/mDBhAiZMmIB9+/bhiiuuQFVVlcu5ysvLMWrUKGRmZuLee+9Fhw4dsGPHDsydOxdZWVm1xq8tXrwYFRUVmDVrFoxGI0JCQhp/JwHw8/PDddddh08//RRHjx5Fr1696jzuvvvuw3fffYcHH3wQPXv2RH5+PrZt24Zjx45h4MCBeOaZZ2A2m5GRkYG33nrLee6zvfjiizAYDHj88cdRWVl53m7fwsJCTJgwAVOnTsUtt9yCb7/9FrNnz4bBYMDMmTMb9Ts2pLazrV+/HuPHj0fHjh3xwgsvwGKx4N1338Xw4cOxb9++WsFk6tSpiIuLwyuvvIJ9+/bhk08+Qdu2bfHqq6/WexsLFizAF198gdWrVzu7ZPv27QugOljOmzcP48aNw+zZs5GYmIgPP/wQu3fvxvbt2126q/Pz8zF+/HjcfPPNuP322xEeHt6o+waoHkcFAKGhoec9r8ViwejRo5GcnIwHH3wQcXFxWLFiBaZPn46ioiI88sgjAKo/9FxzzTXYtm0b7rvvPvTo0QOrV6926S5sirvuugtLlizB+PHjcffdd8Nms2Hr1q34888/MXjwYHz55Ze4++67cdFFF2HWrFkAcMFw0Fg33HAD7rrrLmfX+YWUl5cjLy8PAFBcXIy1a9di3bp1mDt3rvOYzMxM5OTkYPDgwbV+/qKLLsIvv/zi/H7//v3w9fVFjx49ah1Xc/2ll17qcl1+fj7sdjvS09Px3//+FwAwduxY5/VTpkzB7NmzsXTpUkyZMsXlZ5cuXYqYmBgMHz7c5fJevXrh8ccfxyuvvAJ/f3+sW7cOb7/9NqKiouq8H8xms/N+qNGmTZtax61cuRK33XYbRo4ciZ9++gkmk6nO8y1YsACFhYV49tlnsWrVqjqPAao/uP773//G008/jXbt2tV7HKmA4BZIaiVms1kCIF177bW1rissLJRyc3OdX+Xl5c7rxo4dK/Xp08elK8ThcEjDhg2TunTp4ryspltj3LhxksPhcF7+6KOPSjqdTioqKpIkSZJycnIkg8EgTZw40eW4p59+WgLg0lX14osvSr6+vlJSUpJLvU899ZSk0+mcXdU1XUsBAQFSTk5Og+6PC3V7vPXWWxIA6YcffnBeBkB6/vnnnd8HBga6dDvVpb5u1pputY4dO7rc32dft2nTJudlo0aNkgBIb7zxhvOyyspKqX///lLbtm2lqqoqSZL+eRxSUlIueM76aqurW7LmdvLz852XHTx4UNJqtdKdd97pvKymS3XmzJku57zuuuuk0NDQWrd1rrq6ZGv+Zq644gqXLvL33ntPAiB99tlnzstq7qePPvrogrd19u0lJiZKubm5UkpKirRw4ULJaDRK4eHhzm7e+s67YMECCYD01VdfOS+rqqqShg4dKvn5+UnFxcWSJEnS999/LwGQXnvtNedxNptNGjFiRK37etSoUdKoUaNq1Tpt2jSXx2vjxo0SAOnhhx+udezZz62W7AKu0a9fPyk4OLhB567ra/bs2S417969WwIgffHFF7XO88QTT0gAnK9JEydOlDp27FjruLKyMgmA9NRTT9W6zmg0Om87NDRUeuedd2odc+ONN0re3t6S2Wx2XpaQkCABkObOnVvn71heXi517NhRAiANGjSozu7nmudoXV9ni4mJkSIjIyUvLy9p9OjR5x1ykJWVJfn7+zu7xs/Xzfz4449LcXFxzvuPXcDqxS5glaiZ0VhXK8/o0aMRFhbm/Hr//fcBAAUFBdi4cSOmTp2KkpIS5OXlIS8vD/n5+bjyyitx/PhxZGZmupxr1qxZLoPmR4wYAbvdjrS0NADVLUlVVVV46KGHXI6ra5LEihUrMGLECAQHBztvOy8vD+PGjYPdbscff/zhcvz111+PsLCwpt1B56i5n0pKSuo9JigoCLt27cLp06ebfDvTpk2r9xP9uby8vHDvvfc6vzcYDLj33nuRk5ODvXv3NrmGC8nKysKBAwcwffp0l1bVvn374vLLL3dpjalx3333uXw/YsQI5OfnN2lmbc3fzJw5c6DV/vOSdc899yAgIKBWN53RaMSMGTMadRvdunVDWFgY4uLicO+996Jz585Ys2YNfHx8znveX375Be3atcMtt9zivEyv1+Phhx9GaWkptmzZ4jzOy8sLs2fPdh6n0+nw0EMPNarOs61cuRIajcbZbX621p644ufnd97nytlmzZqF33//Hb///jtWrlyJBx54AAsXLsRjjz3mPMZisQCovs/PVdP9WXOMxWJp0HFnW7t2LX755Re88cYb6NChg3OG7tluv/12VFRUuLSmLV26FABcun/PZjAYEBgYCKC6RVGn09V5HAC8//77zvuh5utcBQUFsNlsiI6OPu/rxL///W907NgRd999d73HAEBSUhLefvttzJ8/v877jNSFXcAq4e/vDwAoLS2tdd3ChQtRUlKCM2fO4Pbbb3denpycDEmS8Nxzz+G5556r87w5OTkuXRxnj9cBgODgYADV3ZcAnEGwS5cuLseFhYU5j61x/PhxHDp0qN5Ql5OT4/L9uTPqmqPmfqq53+ry2muvYdq0aWjfvj0GDRqECRMm4M4770THjh0bfDuNqTkyMrLWTMKuXbsCqB63d8kllzT4XI1R85h169at1nU9evTAr7/+irKyMpfazvd3EBAQ4JbbNxgM6Nixo/P6GlFRUY2eQb1y5UoEBARAr9cjOjq6zm7Sus6blpaGLl26uARTAM7uyJra0tLSEBERUesDWF33aUOdOHECkZGRTR7q4E6lpaXnfa6crUuXLi6za6dMmQKNRoMFCxZg5syZ6NOnjzPs1DWTtWbpk5pjTCZTg44725gxYwAA48ePxzXXXIPevXvDz88PDz74oPOY8ePHIyQkBEuXLnWOm/zmm2/Qr1+/eoeFvP3229i/fz969+6Nd955B/fcc0+9s9kvuuiiOru4zzZ27Fh06NABH374IUJCQvD222/XOubPP//El19+iQ0bNtT6OzzXI488gmHDhuH6668/73GkDgyAKhEYGIiIiAjEx8fXuq5mTOC5EwdqJlo8/vjjuPLKK+s877kvbvV94pXOmkzRUA6HA5dffjmefPLJOq+vCT81GtqS1hA199P5liKZOnUqRowYgdWrV+O3337D/Pnz8eqrr2LVqlUYP358g27HnTUD9bf81LXGWkty599BYzXlPh05cmSd46+ae96m0Gg0dd5Prf0YNpTVakVSUlKzFiofO3Ys3nvvPfzxxx/o06ePc5JaVlZWrWOzsrIQEhLibMGKiIjApk2bIEmSy99/zc9GRkae97Y7deqEAQMG4Ouvv3YJgHq9HlOnTsWiRYtw5swZpKen4/jx43jttdfqPM+pU6fw/PPP49prr8UHH3yA7t2744EHHsCvv/7auDvjHO+99x4KCwvxzjvvIDg4uNZi9E8++SRGjBiBuLg452t4zdjCrKwspKeno0OHDti4cSPWrVuHVatWubzW22w2WCwWpKamIiQkpNEf0Ei+GABVZOLEifjkk0/w119/OQdIn09NS5Zer693PazGqllf8Pjx4y4tZbm5uc5WwhqdOnVCaWmp2267oUpLS7F69Wq0b9++1sDyc0VEROD+++/H/fffj5ycHAwcOBAvvfSSMwC6syvu9OnTtVrakpKSAPwzk7Gmpe3c2aXntpI1praaxywxMbHWdQkJCWjTpk2tlkl3Ovv2z/6bqaqqQkpKSqv/fZwtJiYGhw4dgsPhcGl9SUhIcF5f8++GDRtQWlrq0gpY130aHByMkydP1rr83MewU6dO+PXXX1FQUHDeVsCW7g7+7rvvYLFY6v2Q2BA2mw3APy3vUVFRCAsLq3Mh47/++gv9+/d3ft+/f3988sknOHbsGHr27Om8vGZB97OPrY/FYqmzFfG2227DRx99hOXLlyMlJQUajcalu/9sNeHxnXfeQUREBF566SU89NBDWLZsmctahI2l1WrxxRdfwGw2Y968eQgJCcHDDz/svD49PR1paWl19iZcffXVCAwMRFFREdLT0wGg1qQWoHrSTVxcHN56661GrVlK8sYxgCry5JNPwsfHBzNnzsSZM2dqXX9uq0Pbtm0xevRoLFy4sM5P4g3dAeBs48aNg16vx7vvvutye3XtSDF16lTs3Lmzzk/QRUVFzjcNd7JYLLjjjjtQUFCAZ5555rwtamaz2eWytm3bIjIy0uWNxNfXt9ZxTWWz2bBw4ULn91VVVVi4cCHCwsIwaNAgAP/M8Dx7fKTdbq9zR42G1hYREYH+/fvj888/dwmW8fHx+O2335yL+raUcePGwWAw4J133nH5m/n0009hNpsxceLEFr3985kwYQKys7NdZrnbbDa8++678PPzw6hRo5zH2Ww2fPjhh87j7HY73n333Vrn7NSpExISElyeXwcPHsT27dtdjrv++ushSRLmzZtX6xxn30++vr51LjfjDgcPHsScOXMQHByMBx54oMnn+emnnwBULytT4/rrr8fPP/+MU6dOOS/bsGEDkpKScOONNzovu+aaa6DX6/HBBx84L5MkCR999BGioqIwbNgwANWPy7kfMoHqQHn48OE6u2OHDx+O2NhYfPXVV1i+fDlGjRqF6OjoWsetXr0aP/74I/773/86l9G6//77MWjQIDz22GPN3lVGr9fju+++w/DhwzFnzhx8+eWXzus+/vhjrF692uWrZmzp66+/jq+//hpA9dJG5x63evVqhIWFYfDgwVi9ejUmT57crDpJXtgCqCJdunTB0qVLccstt6Bbt27OnUAkSUJKSgqWLl0KrVbr8gL3/vvv49JLL0WfPn1wzz33oGPHjjhz5gx27tyJjIwMHDx4sFE1hIWFOZdKmDRpEiZMmID9+/dj7dq1tbrgnnjiCfz444+YNGkSpk+fjkGDBqGsrAyHDx/Gd999h9TU1At2251PZmYmvvrqKwDVLQ9Hjx7FihUrkJ2djX/9618uEy7OVVJSgujoaNxwww3o168f/Pz8sH79euzevRtvvPGG87hBgwZh+fLleOyxxzBkyBD4+fk1+UU2MjISr776KlJTU9G1a1csX74cBw4cwMcff+xcBqVXr1645JJLMHfuXGfL0LJly+oMy42pbf78+Rg/fjyGDh2Ku+66y7kMTGBgYIvvjxwWFoa5c+di3rx5uOqqq3D11VcjMTERH3zwAYYMGeIybrW1zZo1CwsXLsT06dOxd+9exMbG4rvvvsP27duxYMEC57i4yZMnY/jw4XjqqaeQmpqKnj17YtWqVXUG8JkzZ+LNN9/ElVdeibvuugs5OTn46KOP0KtXL5cgMWbMGNxxxx145513cPz4cVx11VVwOBzYunUrxowZ42yRGjRoENavX48333wTkZGRiIuLa9RSUDW2bt2KiooK2O125OfnY/v27fjxxx8RGBiI1atXN3hJkX379jmfdyUlJdiwYQNWrlyJYcOG4YorrnAe9/TTT2PFihUYM2YMHnnkEZSWlmL+/Pno06ePy2Sc6OhozJkzB/Pnz4fVasWQIUPw/fffY+vWrfj666+dwxFKS0vRvn173HTTTejVqxd8fX1x+PBhLF68GIGBgXWOc9ZoNLj11lvx8ssvA4BzyZizlZSU4OGHH8aAAQNcWua0Wi0++ugjXHzxxXjmmWfqDPuN4ePjgzVr1mDUqFGYOXMmAgMDcfXVV7vcZzVqAv+oUaOcwbZDhw61xuYC1RPwwsPDm71TDMmQmMnHJFJycrI0e/ZsqXPnzpK3t7dkMpmk7t27S/fdd5904MCBWsefOHFCuvPOO6V27dpJer1eioqKkiZNmiR99913zmPqW3agruVH7Ha7NG/ePCkiIkIymUzS6NGjpfj4+Dp3AikpKZHmzp0rde7cWTIYDFKbNm2kYcOGSa+//rpz6ZP6dhg4n5iYGOfSCxqNRgoICJB69eol3XPPPdKuXbvq/BmctQxMZWWl9MQTT0j9+vWT/P39JV9fX6lfv361dg8pLS2Vbr31VikoKEgC4FzG43xLa9S3DEyvXr2kPXv2SEOHDpW8vb2lmJgY6b333qv18ydOnJDGjRvnXMrk6aefdu6gcPY566utvt0p1q9fLw0fPlwymUxSQECANHnyZOno0aMux9S3s0Z9y9Ocq76fl6TqZV+6d+8u6fV6KTw8XJo9e7ZUWFjockxjd0w53+019LxnzpyRZsyYIbVp00YyGAxSnz596tzZIz8/X7rjjjukgIAAKTAwULrjjjuk/fv313lff/XVV1LHjh0lg8Eg9e/fX/r1119rLQMjSdVLycyfP1/q3r27ZDAYpLCwMGn8+PHS3r17ncckJCRII0eOlEwmU62lls51vmVgar70er0UFhYmjRw5UnrppZcavPRSXcvAeHl5SR07dpSeeOIJqaSkpNbPxMfHS1dccYXk4+MjBQUFSbfddpuUnZ1d6zi73S69/PLLUkxMjGQwGKRevXq5LM0jSdXP2UceeUTq27evFBAQIOn1eikmJka66667zvt3eeTIEQmAZDQaa/29SZIkPfLII5JWq5X++uuvOn/+wQcflLRarbRnzx5Jkpq+E0iN7Oxs52v32c/nszX0Ns53O6R8GklqhVHZREREROQxOAaQiIiISGUYAImIiIhUhgGQiIiISGUYAImIiIhUhgGQiIiISGUYAImIiIhUhgGQiIiISGUYAImIiIhUhgGQiIiISGUYAImIiIhUhgGQiIiISGUYAImIiIhUhgGQiIiISGUYAImIiIhUhgGQiIiISGUYAImIiIhUhgGQiIiISGUYAImIiIhUhgGQiIiISGUYAImIiIhUhgGQiIiISGUYAImIiIhUhgGQiIiISGUYAImIiIhUhgGQiIiISGUYAImIiIhUhgGQiIiISGUYAIlInRyS6AqIiITxEl0AEVGDOCSgrAoorQLKrH//W8f/LVbA5nD9sjoA+zmX1eQ/nQbQaav/9dLW/r+XFjDqAF8D4Kv/518fvetlPnrA31D9M0REHk4jSRI/BhOReFY7kG8B8std/y34+/+lVf+ENk+lARDoDYSagJA6vkJ9AINOdJVERAyARNSKHBKQVw5klQBZpdX/5v0d9EoqPT/guYOfAWjjA7TzAyL9//kK8hZdGRGpCAMgEbUIc7kVR7OKcezvrysrHBi3J7u6O5ZqM3lVB8EIf9dg6GcQXRkRKRDHABJRs9nsDhzLKsGetALsTSvE/vQiZBZZXI4xhfljHMNf/Sw24ERh9dfZQk1AXDAQGwTEBAIdAgE9u5GJqHnYAkhEjWYut2JfeiH2phViT1oBDmWYUV5lP+/PRBl02J53/mOoAXQaoH0g0CkY6BgMdAoBAoyiqyIimWEAJKILMpdbsS05D9uS87AntQDJuaVoyivHCY0ROnOl+wtUu7a+QLdQoEdY9b8mveiKiMjDMQASUS0Oh4SDGUX4IykPW5JycDDDDLsb1s3bGxyI0DSzGyqkemk1QFxQdRjs0QaICaq+jIjoLAyARAQAyCmpwJbEXPxxPA/bjueisNzq9ttYFRmCgQkFbj8vnYePvrpVsGdYdSgMMYmuiIg8ACeBEKnYidxS/HIoC2vjs3Esu7hJ3bqNcURyYGDL3gSdq9wK7M+u/gKqJ5EMjAAGtAPCfMXWRkTCsAWQSGVO5pZizaEsrDmchYTskla97fHBPvgwrbxVb5POIzqgOggOjADC/URXQ0StiAGQSAVS8sqw5tBprDmcjWNZxcLq8NVqEF8MaLgPr+eJ9P+nZTDCX3Q1RNTCGACJFCqnuAIr92Xix4OnhYa+cyUafWDMZSugR4v0By6JBi6OAvy5xAyREjEAEimI3SFhY0IOlu8+hc2JObB5YEvbtrAgRJ8oEl0GNYROA/RuCwxrD/Rqy9nERArCSSBECpCWX4blu09h5b4MnCn27HX2Tuq1iBZdBDWMXQIOnqn+CjQCF0dXh8G2nDxCJHdsASSSqQqrHevis7Fsdzp2pRS0+Axed3k0PBCPHOdagLLWKbg6CA6KBAzclo5IjhgAiWTmdJEFi7en4Ns9GTBb3L9WX0sb6GfEqtOe3UpJDeSrB4Z3AEbHAkHeoqshokZgACSSiUMZRVi0NQVrD2d55Ni+xkip8oKmwia6DHIXnaZ6BvFlcdU7jxCRx2MAJPJgDoeE34+dwSdbT2J3aqHoctwm3t8ffpmtuwYhtZJOwdVBsF87Thoh8mCcBELkgcqrbFixJwOLt6cgNV95S6Zk+Xqhi+giqGWcKKz+CjUBY+Kqxwp6862GyNOwBZDIg5jLrfhk20l8sTNNluP7Guq9qBBMOsY9gVXB5FXdInhZHGDSi66GiP7GAEjkAYorrPhkawoWb09BiQrGxk1r4495J9kFrComL2BsR2BMLIMgkQdgACQSqLTShs+2peCTrSdRrILgVyPKoMP2PLvoMkgEH311ayCDIJFQDIBEApRV2rBkRyoWbT2JonLldvWezwmNETozl4NRLQZBIqEYAIlakaXKjs93puLjP06ioKxKdDlC7Q0ORGgaF4RWPd+/g+DYjlxUmqgVMQAStQKHQ8J3+zLw+q+JyClhqxcArI4MwYAETgShvwV5A1d3Ay6OAjRcPoaopXFuPlEL23UyHy+uOYr4zGLRpXiUI5AwQHQR5DmKKoAvDgKbU4HrewBdQkVXRKRobAEkaiGnCsrx0ppjWHckW3QpHmlCsC8+SCsTXQZ5qv7tgOu6A2G+oishUiQGQCI3K6mw4r1NyVi8PRVVNofocjyWr1aD+GJAI/Nt7agFeWmBUTHAhC6cKELkZgyARG7icEhYtvsU3vw9EXml6p7g0VCJRh8Yc5W30wm5mZ8BmNgFGBHD7eWI3IQBkMgN4jPNeGrVIY7za6RtYUGIPlEkugySi5hA4NY+QPtA0ZUQyR4DIFEzWKrseGt9Ej7dlgI7uzIb7YuoEIzklnDUGFpN9bIxk7py2RiiZuAsYKIm2no8F0+vPoxTBRbRpcjWQbsdI0UXQfLikID1J4H9WcAtfYCeYaIrIpIltgASNVJBWRX+9/NRrNqfKboU2Rvsb8R3mVwXkZphSCRwQ0/A3yi6EiJZYQAkaoTV+zPw4s/HVL+Lh7toAJys1EFTyX2BqRl89cCUHsDQ9qIrIZINBkCiBjhdZMG/Vx7C1uN5oktRnHg/P/idLhVdBilBt1Dgjn5AiEl0JUQejwGQ6AJ+OJCJ576PR3GFTXQpivR7u2B0SSoUXQYphckLmNoLuDhadCVEHo2TQIjqUVxhxX++j8f3B06LLkXREnUadBFdBCmHxQZ8fhA4dKZ6koifQXRFRB6JAZCoDn+lFODR5QeQWcQZvi1td5UVk0QXQcqzPxs4UQjc2Y8zhYnqwC5gorNY7Q689XsSPtpyAlzWr3VEG72wLZfd69RCNADGxAHXdAP0XDeQqAYDINHfTuSW4tHlB3Aowyy6FNU5ASN0xVwOhlpQdAAwoz8Q4S+6EiKPwABIBODb3afw/I9HYLFyORIR9gYHIjSNwZtamF4L3Nyby8UQgWMASeUqbXb85/sjWL7nlOhSVO2USYdQ0UWQ8lkdwJeHgJOF1TOF2SVMKsYASKqVUViO+7/exy5fDxAPCf1FF0Hqsf0UcKoYmDWIawaSamlFF0Akwh9JuZj87jaGPw+xw8KdVaiVpZuBV7YCR3NFV0IkBMcAkqpIkoT3NyXjzd+TOMvXg/hqNYgvBjR8UKi1aQBM6gpc1RnQaERXQ9RqGABJNYorrHhs+UGsP3ZGdClUh0SjD4y55aLLILXq3RaY3h/w0YuuhKhVsAuYVCExuwTXvLed4c+D5QVwxwYSKD4H+L9twOkS0ZUQtQoGQFK8LUm5uP7DHUjJKxNdCp3HST1fjkiwvHLg9R0cF0iqwFdcUrRv/krHXUt2o7SSO014ugMOrsFIHqDCBnywG9iWLroSohbFAEiKJEkS/m9tAuauOgwbJxbIwpayCtElEFVzSMDSw8D3CQCHyZNCcRIIKU6F1Y5/rTiINYeyRJdCjaABcLJSB00lWwLJgwyMAKb146LRpDgMgKQoBWVVuOeLPdibVii6FGqCeD9/+HEQPnmauCDgvsGAv1F0JURuwy5gUoyTuaW47oPtDH8yluXHJTjIA6UUAfN3AGdKRVdC5DYMgKQIe9MKMeXDHUjL5zpycpakZYcEeai88uoQeJIfMEkZGABJ9rYn5+GOT3ehqNwquhRqpt1WztYmD1ZuBd7dBSTmia6EqNkYAEnWNhw7g5lLdqO8ihMHlGBjiUV0CUTnV2mvXibmMBeVJ3njJBCSrZ8Pncajyw/AauefsJKcgBG64krRZRCdn04DzBhQPUuYSIbYAkiytGLPKTyyjOFPiYqCvUWXQHRhdgn4bD+w85ToSoiahAGQZOeLnal4cuUh2LnAsyKdMnG9NZIJhwR8dQjYnCq6EqJGYwAkWfloywn854cjXJxfwY6ADy7JiATg2yPAr8miKyFqFAZAko23fk/C/61NEF0GtbCdlirRJRA13g+JwM9JoqsgajAGQJKFDzYn4+0Nx0WXQa1gU3E5JK1GdBlEjffLceC3E6KrIGoQBkDyeJ/vSMVr6xJFl0GtpMwuoSrEJLoMoqb5PgHYkiq6CqILYgAkj7Zizym88NMR0WVQK8sLNIgugajpvj0C/Jkhugqi82IAJI/186HTeGrVYU74UKGTer40kYxJqJ4dvC9LdCVE9eKrLHmkDcfO4NHlB7jUi0odcHBnF5I5hwQs3s8dQ8hjMQCSx9mRnIf7v97HRZ5VbGtZhegSiJrPLgGf7OPeweSRuBUceZS9aQW449O/uLevymkAnKzUQVPJvwNSAKMOeOhioGOw6EqInNgCSB4jOacUM5fsYfgjSADKQjkTmBSi0g58uBs4Uyq6EiInBkDyCPmllZi5ZDfMFqvoUshDZPvqRZdA5D5lVuCD3UApFzonz8AASMJVWO2454s9SC8oF10KeZBEbglMSpNbDny0B7Cyl4PEYwAkoSRJwmPfHsC+9CLRpZCH2W21iS6ByP1OFgKfHwTXtyLRGABJqP9bl4BfDmeLLoM80MYSi+gSiFrGvqzqvYOJBGIAJGG++SsdC7ecFF0Geaj0ChvsAUbRZRC1jN9OANvSRVdBKsYASEL8kZSL576PF10GeThzsLfoEohazrJ44Giu6CpIpRgAqdUlZpfgga/3wcZdPugCTpk4E4QUzPH3QtGnS0RXQirEAEitymyx4p4v9qCkkgP86cKOcKA8KV2FDVi4B+ASWNTKGACp1UiShMeWH+ByL9RgOyq4ZhqpQG45ZwZTq2MApFbz7sZkbEjIEV0Gycim4nJIWo3oMoha3qEzwLpk0VWQijAAUqvYkpSLBeuTRJdBMlNml2AN4ZZwpBI/JwHHOCmEWgcDILW4jMJyzFm2H5zzQU2RF2gQXQJR65AAfLYfyOcwGWp5DIDUoiptdtz/9T4UlnOAMzXNSQNfpkhFyqzAon3cLo5aHF9ZqUU9/8MRHMowiy6DZOyAnW+EpDLpZuDbI6KrIIVjAKQWs3x3OpbtPiW6DJK5P8oqRJdA1Pq2nwJ28PWTWg4DILWIpDMl+M8P/ARLzbe7pBKSkQtCkwp9ewQ4Uyq6ClIoBkByu0qbHQ9/sx+VNofoUkgBJABloZwJTCpUZQcWHwDsfC0l92MAJLf7v7UJSMjm1kbkPtl+etElEImRbq5eHobIzRgAya02J+ZgyY5U0WWQwiTpuBg0qdhvJ4DkAtFVkMIwAJLbFJRV4YnvDnE3I3K7PVVcRohUTAKw5AD3Cya3YgAkt3l61WHkllSKLoMUaGOJRXQJRGIVWIBl8aKrIAVhACS3WLk3A+uOZIsugxQqtcIGuz93BCGV230a2HNadBWkEAyA1GyZRRa88COXfKGWZeaewETAN4erWwOJmokBkJpFkiQ8seIgSiptokshhTtl4lqARLDYgC8Piq6CFIABkJplxZ4M7DiRL7oMUoEj4OwiIgBAYj53CaFmYwCkJssrrcTLa4+JLoNUYmdFlegSiDzHyqOAmdskUtMxAFKTvfjzURSVc1kCah2bzeWQtFwPkAhAdVfwtxx7TU3HAEhNsiUpFz8c4Gw0aj0ldglWTgQh+sf+bOAAV1+gpmEApEazVNnx7PeHRZdBKpQXwKVgiFx8ewSo4CQ8ajwGQGq0BeuTcIrLEJAAJ418ySJyUVQB/JgougqSIb6aUqMcPV2MT7eliC6DVOqA3S66BCLPsyUVSDeLroJkhgGQGszhkDB31SHYHFyOg8TYWsatBolqkQB8fQjgazM1AgMgNdjXu9JwMIOfMkmcv0oqIBm5IDRRLaeKgW3poqsgGWEApAYxW6x4a/1x0WWQykkAykM5E5ioTj8nARYuzUUNwwBIDfLexuMoKONCvCRetq9edAlEnqm0ClibLLoKkgkGQLqgtPwyfL4jTXQZRACAJB0Xgyaq1+ZUIK9cdBUkAwyAdEGv/JKAKrtDdBlEAIDdVnZxEdXL5gBWc4tOujAGQDqvXSfzse4IV5onz7GxhGtQEp3X/mzgeL7oKsjDMQBSvSRJwv/W8JMkeZbUChvs/twRhOi8Vh4DJC4LQ/VjAKR6rdyXicOZXPaFPI852Ft0CUSeLd0M7MoUXQV5MAZAqpOlyo7Xf+X2QuSZMkxeoksg8nw/JACV3CeY6sYASHX6dNtJZBdXiC6DqE5HNOzaIrogcyWwKVV0FeShGACplpIKKxZt5X6/5Ll2VnBNSqIG2XASqGArINXGAEi1LN6eCjNXkycPtslcDknL9QCJLqjMCmziB3qqjQGQXBRXWPHpNr5YkGcrsUuwhnBLOKIG2ZDCLeKoFgZAcrF4G1v/SB7yArgUDFGDlFs5FpBqYQAkp+IKKz7bztY/kocUA1++iBpsI1sByRVfQcmJrX8kJwcddtElEMkHWwHpHAyABKBm7N9J0WUQNdjW8krRJRDJy4aT1UGQCAyA9LfPtqWgmEsFkIz8WVwByaATXQaRfFhs1V3BRGAAJACllTZ8xpm/JDMSgPI2nAlM1CibUrguIAFgACQAy3efYusfyVK2r150CUTyYrEBO0+JroI8AAOgyjkcEpbsYOsfyVOSjotBEzXaplTAwe0U1Y4BUOV+O5qNUwUW0WUQNckeK1uuiRotrxw4dEZ0FSQYA6DKcdcPkrNNpfzwQtQknAyiegyAKnYoowi7UwtFl0HUZCctVtj9uSMIUaMlFwDpZtFVkEAMgCrG1j9SguJgb9ElEMnTBq79qmYMgCqVba7AL4ezRJdB1GynTF6iSyCSp31ZQFGF6CpIEAZAlfp8Zyqsds4CI/k7ouHfMVGT2CVgc6roKkgQBkAVslTZ8c1f6aLLIHKLPyuqRJdAJF/b0oEq7qutRgyAKvTzodMo4n6QpBAbzeWQtFwPkKhJyq3VXcGkOgyAKrRiT4boEojcpsQuwRrCiSBETcadQVSJAVBlUvLK8FdqgegyiNwqP8AougQi+TpeAOSUia6CWhkDoMp8u4ef9Eh5Ugx8KSNqFrYCqg5fNVXE7pCwah+7f0l5Djg4iJ2oWf7M4P7AKsMAqCKbE3NwprhSdBlEbre1nH/XRM1irgSO5IiugloRA6CKsPuXlOrP4gpIBp3oMojkbQffI9SEAVAl8korsTGBn+5ImSQA5aEm0WUQyVt8DlDC1nS1YABUidX7MrnzBynaGT+96BKI5M0uAbsyRVdBrYQBUCW+28vJH6RsSV5cDJqo2f7ke4VaMACqQHJOCRLPlIgug6hF7amyiS6BSP5OlwDZpaKroFbAAKgCvxzOFl0CUYvbWGoRXQKRMuzn1nBqwACoAr8c5pOZlO+kxQq7v0F0GUTyx72BVYEBUOFO5pYiIZvdv6QOxcHcE5io2TJLuDWcCjAAKtzaeHb/knpkmLxEl0CkDGwFVDwGQIVbc4hPYlKPIxoudUTkFgyAiscAqGBp+WU4mlUsugyiVvNnhVV0CUTKkFEM5LIbWMkYABWMs39JbTYVl0HScj1AIrdgK6CiMQAqGGf/ktqYbRKsIZwIQuQW+9mIoGQMgAqVba7A4Uyz6DKIWl1+gFF0CUTKkG4GCrm+plIxACrUH0m5oksgEiLFyJc1Irc5lie6AmohfKVUqC3HGQBJnQ7a7aJLIFKOo3wvUSoGQAVyOCRsT+anNlKnbeWVoksgUo7EPMDB5ZWUiAFQgQ5lmlFUzuUwSJ3+LK6AZNCJLoNIGcqs1WMBSXEYABWI4/9IzewAykNNossgUg52AysSA6ACbeX4P1K5M3560SUQKccxvqcoEQOgwpRUWLE/vUh0GURCJXlxMWgit0kpAiwcVqQ0DIAKs+NEPmwcsEsqt8dqE10CkXI4JCAxX3QV5GYMgArD8X9EwKZiLl5L5FYcB6g4DIAK8+dJfkojOlFhhcPPILoMIuVI4nuL0jAAKkhReRVO5pWJLoPII5i5JzCR++SUAaVVoqsgN2IAVJB96YWQOPyPCACQYfISXQKRsqQUiq6A3IgBUEH2pRWJLoHIYxzR8NMQkVudZABUEgZABdmbxicnUY0/K7hsBZFbpRSJroDciAFQIewOCQczikSXQeQxNhWXQeJygETuk1akyn2BY2NjsWDBAtFluB0DoEIcyypGeZVddBlEHsNsk2AN4ZZwRG5TaQcyi1v0JqZPnw6NRlPrKzk5uUVvV40YABViXzq7f4nOVRBoFF0CkbK0wjjAq666CllZWS5fcXFxLX67asMAqBD7OP6PqJYUA1/iiNyqFcYBGo1GtGvXzuVLp9Phhx9+wMCBA+Ht7Y2OHTti3rx5sNn+2fVHo9Fg4cKFmDRpEnx8fNCjRw/s3LkTycnJGD16NHx9fTFs2DCcOHHC+TMnTpzANddcg/DwcPj5+WHIkCFYv379eesrKirC3XffjbCwMAQEBOCyyy7DwYMHW+z+aCl8dVSIvWwBJKrloIPDIojcStBM4K1bt+LOO+/EI488gqNHj2LhwoVYsmQJXnrpJZfjXnzxRdx55504cOAAunfvjltvvRX33nsv5s6diz179kCSJDz44IPO40tLSzFhwgRs2LAB+/fvx1VXXYXJkycjPT293lpuvPFG5OTkYO3atdi7dy8GDhyIsWPHoqCgoMV+/5agkSSuHCd35nIr+v33N9FlEHmc4QHe+DqjQnQZRMry2uVAC+20M336dHz11Vfw9v5nIffx48ejsLAQY8eOxdy5c52Xf/XVV3jyySdx+vRpANUtgM8++yxefPFFAMCff/6JoUOH4tNPP8XMmTMBAMuWLcOMGTNgsdS/XWTv3r1x3333OYNibGws5syZgzlz5mDbtm2YOHEicnJyYDT+M8Skc+fOePLJJzFr1iz33RktjCulKkDimRLRJRB5pD+LKyAZdNBwghSR+2QWA93atNjpx4wZgw8//ND5va+vL/r27Yvt27e7tPjZ7XZUVFSgvLwcPj4+AIC+ffs6rw8PDwcA9OnTx+WyiooKFBcXIyAgAKWlpXjhhRewZs0aZGVlwWazwWKx1NsCePDgQZSWliI0NNTlcovF4tK1LAcMgAqQmN2ys7KI5MoOwBJqgk9WqehSiJQjs6RFA6Cvry86d+7scllpaSnmzZuHKVOm1Dr+7NZCvV7v/L9Go6n3MofDAQB4/PHH8fvvv+P1119H586dYTKZcMMNN6Cqqu5t70pLSxEREYHNmzfXui4oKKhhv6CHYABUALYAEtUv20+PjqKLIFKSFl4Kpi4DBw5EYmJirWDYXNu3b8f06dNx3XXXAagOeKmpqeetIzs7G15eXoiNjXVrLa2NAVABErMZAInqc1ynYQAkcqfM1n/P+c9//oNJkyahQ4cOuOGGG6DVanHw4EHEx8fjf//7X5PP26VLF6xatQqTJ0+GRqPBc88952wdrMu4ceMwdOhQXHvttXjttdfQtWtXnD59GmvWrMF1112HwYMHN7mW1sZZwArAAEhUv71nLRNBRG6QVdLqO4JceeWV+Pnnn/Hbb79hyJAhuOSSS/DWW28hJiamWed98803ERwcjGHDhmHy5Mm48sorMXDgwHqP12g0+OWXXzBy5EjMmDEDXbt2xc0334y0tDTnmEO54CxgmcsyWzD0lY2iyyDyWJ289diQw32Bidxq3mggzFd0FdQMbAGUObb+EZ3fiQorHC20ZAWRanFilewxAMocAyDRhZlDvC98EBE1XDYDoNwxAMocZwATXViGifPdiNwqi+89cscAKHMnc8tEl0Dk8Y5qONSZyK3O8L1H7hgAZS6jsP7tbIio2q7Kuhd1JaImyi8XXQE1EwOgjFVY7cgrrRRdBpHH22Auh6QRXQWRgpRUAdxiUdYYAGWMrX9EDWO2SbCGmESXQaQsBXwPkjOOjJaxjEI2wRM1VEGgEe3y+YYlFy/s/hrz9nzjclm3oGgk3PIRAKDCVoV/7fgUy5L/QKXdiivbD8QHI2cj3Ce43nOuOrkDHx1Zi725ySioLMH+G99B/zau+8Q8tn0RliRugK+XN/7vkmm4resY53UrTmzDF4kb8NOE5934m8pYgQVo5ye6CmoiBkAZyyzimxlRQ6UYtGgnughqlF7BHbD+6pec33tp/um0enT7IqxJ34MVVzyFQKMvHtz6Iab8+jK2Xze/3vOVWStwaURPTO10Ke7Z8m6t639K3YWlx7fgt0kv4rj5NGZuehtXth+INqZAmCvL8MyuL7B+ctO3HVMctgDKGgOgjLELmKjhDjocGCq6CGoUL60O7epo0TNXluHThN+xdNzjuCy6HwBg8Zg56LFsNv7MTsAl7brXeb47ul0GAEgtPlPn9ccKT2F0VB8MbtsFg9t2wZzti5BScgZtTIF48s/FmN1rAjr4t3XTb6cAnAgiaxwDKGMMgEQNt83CCVNyc9x8GpGf34mOX92F29bPR3pJDgBgb24yrA4bxkX3dx7bPbg9OviFYeeZhCbfXr/QOOzJSUZhZSn25ibDYqtE58BIbMs6gn25J/Bwn8nN/ZWUhS2AssYWQBnjGECihttptkAy6KDhzEVZuLhtNyy57FF0C4pCVlkB5u35BiO+/zfib3of2eWFMGi9EGR0HX8W7hOE7PLCJt/mlR0G4fauozHku0dh8jLg88seha+XEbP/+ABLLnsUHx75Be8e/hltTAH4eNSD6BUS09xfU944plbWGABljC2ARA1nB2AJNcGHe5jKwviYwc7/9w2Nw8Xh3RDz1Ux8e2IbTLqW29v5hSG34YUhtzm/n7d7KcZF94deq8P/9i7H4Zvex89pf+HODW9i741vt1gdssAWQFljF7BM2ewOrgFI1Ehn/PSiS6AmCjL6oWtgFJLNp9HOJxhVDhuKKl3D/JnyojrHDDZVQuEpfHV8E1686HZszjyMkZG9EWYKxNROI7Av7wRKqlTeC2OuAOwO0VVQEzEAylSRxQqJu1sRNUqSjqtBy1Wp1YITxVmI8AnBoLDO0Gu9sCHjoPP6xMIMpJfmYmh43RNAGkuSJNy75X28Oexu+OlNsEsOWB02AHD+a5dUHn4kAGVW0VVQEzEAylRRObe2ImqsvTab6BKogR7f8Sm2nD6M1OIz2JF9DNetewk6jRa3dBmFQKMv7up+OR7b8Qk2ZR7C3txkzNi0AEPDu7vMAO7+zX1YfXKH8/uCihIcyDuJo4XpAIDEogwcyDtZ57jBT479ijBTACbHXgwAGN6uBzZmHsKf2Ql46+AP6BncodYYRFUq43uRXHEMoEwVlvNTF1FjbSqx4GnRRVCDZJTl4Zbf5yO/ohhhpkBcGtETf055A2GmQADAW8PvgVajxfW/vnzWQtD3u5wjsSgD5rO6aX9M3YUZmxY4v7/599cAAM8PvsVl3N+Z8kK8tO9b7DhrTcGLwrvhX/2uw8Rf5qGtKRCfX/ZoS/za8sMWQNnSSBI7EuXotyPZmPXlXtFlEMnOSYcB2lK2WhC5xb2DgH5cYl2O2AUsU0VsASRqkuIQb9ElECkHWwBliwFQpgo5BpCoSTJMHPlC5DYcAyhbDIAyxTGARE1zVMNRL0RuwxZA2WIAlCnOAiZqmj8r+dwhchu2AMoWA6BMFfBJR9QkG8zlkLgcIJF7sAVQthgAZcps4ZOOqCnMNgm2EJPoMoiUgY0RssUAKFOVNpWvQE/UDPmBRtElEClDpV10BdREDIAyVcUASNRkqQa+9BG5BfcCli2+CsqUlU86oiY7pPY9XInchY0RssUAKFNVDIBETba1rFJ0CUTKYOeySnLFAChT7AImarodxRZIBp3oMojkj+9FssUAKFPsAiZqOjsASyhnAhM1m4MtgHLFAChTnAVM1Dxn/PSiSyCSP74XyRYDoEyxBZCoeY57cTVoombje5FsMQDKFMcAEjXPXqtNdAlE8sf3ItliAJQhu0PisAuiZtpUYhFdApH8cRawbDEAypCWPVdEzZZkscLhy3GARM3GFglZYgCUIY1GAy+mQKJmK+GewETNo9WwVUKmGABlSq/jQ0fUXFk+XqJLIJI3HcOfXDFFyJSeTzqiZkvUsOuKqFm8GCPkio+cTBn4pCNqNs4EJmomvhfJFh85mWIXMFHzbeZMYKLmYQCULT5yMsUASNR86RU22P0Nossgki8GQNniIydTHANI5B7Fwd6iSyCSLwZA2eIjJ1NsASRyj9MmzgQmajK+F8kWHzmZYgAkco8EzgQmajq2AMoWHzmZ8jXqRJdApAi7q6yiSyCSLz1jhFzxkZOpIBMHrhO5w5ZizgQmajIfbqcoVwyAMhXMPUyJ3CKryg57oFF0GUTy5MvGCLliAJSpQLYAErlNURBnAhM1iR/fi+SKAVCmgtnsTuQ2md4cU0vUJOyNki0GQJkKYgAkcptjnAlM1DTsApYtLoAlU0E+fNKdy/znChRt+Rz+g65GyLhZAABrYRYKN32KyoyjkOxWmOIGIeTye6HzDa73PI7KchRt/Qrlx3fCUW6GoW1HBI+bBWNE139ua9cqFP+1EgAQePH1CLhoivO6ytOJKPjtA7S7801otGxZkoO/Kqtwk+giiOSILYCyxRZAmQoy8Ul3tsqsJJQcWAd9WKzzMkdVBXK+fQ7QaBB+y8tod/t8SA4bclb+F5LkqPdc+eveRUXqAbSZ9C9EzHwP3nEDcGbZs7CV5AEAqnJSYN72Ndpc/STaTH4CRVu/QlVuKgBActiR/+v7CLnyAYY/GdlcbIHEzXWIGo9jAGWLAVCmgtns7uSosiDvp9cRetVD0Hr7OS+vzDwKmzkHbSY8CkNYLAxhsWgz8VFUZSWjIu1Q3eeyVqI8cTuCxsyAd/ve0AdHIujS26APjkDJ/rUAAGt+BvRhsTDF9IMptj/0YbGw5mcAAIp3rYR3+14urYXk+fKtDtgDORGEqNH4XiRbDIAyxRbAfxT8/iFMnYbAFNvf5XLJXr3Ar0b3z32l0RkAjQaVGUfqPpnDDkgOl58BAI2X0fkzhrBY2AozYSvOgc2cA1tBJgxtYmAtzELp4fUIGnGH+345ajWFQVwKhqjR2AUsWxwDKFPBvgZoNYBD5WPXy45uQVX2CURMe6vWdcbI7tDovVG4eTGCRt0JSEDRliWA5IC9tLDO82mNPjBGdod5xzLoQ9tD5xuEsmN/oPJ0AryCIwAA+jbtETTyTpxZ/hwAIGjUNOjbtMeZZc8gePQMWFL2wbx9KaD1Qsi4WfBu37vFfn9yn1PeOoSJLoJITjRgC6CMMQDKlF6nRZi/EWeKK0WXIoytOBcFGxYh/KYXofGq/SKk8wlE2LVPoeC3D1Cy9ydAo4Fvz1EwhHcCNPUP+Aqd9C/kr30bmR9MAzRaGNp1gm+PkajMTnYe4z9gAvwHTHB+X3p4AzQGE4xR3ZG56D5E3Pkm7CX5yPvxNUTd+yk0XvyU7OmOQcJA0UUQyUmAEdBy8KxcMQDKWHSwj6oDYFV2MhzlRcha8sg/F0oOVJ46gpJ9P6PD46thihuIqHs/gb3cDI1WB623H069dzt8gtrVe159cATa3fp/cFRVwFFVDi+/EOT+8Cr09fyMvdwM8/alCL/1VVSeToI+JBL6kCjoQ6Ig2W2wFmbCcNbkFPJMuyqqcJvoIojkJMQkugJqBgZAGYsKMmFvWt1dmWrgHdMPETPfc7ks/5e3oQ+NRsDF17vMwtX5BAIALGkH4Sgzw6fzxRc8v9bgDa3BG/aKUlhS9iF49Iw6jyvc+An8h1wLr4A2qMpOgmS3/3Olww446p9xTJ5jS3E5JA3AJQGJGijUR3QF1AwMgDIWFazuT19ao0+tljWN3gitt7/z8tJDv0Mf2h5an0BUnk5A4fqP4T/kGuhDo50/c2bZ0zB1GYqAQZMBAJaTewEAXiFRsBVmoXDzZ9CHRMOvz7haNVhS9sNakInQiY8CAAztusJWkAHLiT3Vy8ZodfAKiWqB357czWyTYAs2QV9gEV0KkTywBVDWGABlLCqIT74LsRZkovCPz+GwlMIrsC0Ch06F/5BrXY8pzIbRUuz83lFZjqI/PoetJA86b3/4dBuGoJF3QqNzfbo4rJUoWP8Rwq7+NzSa6gn1XgFtEDzuXuStXQCNTo/QiY9Cq+fsUrkoCDQgnAGQqGFC+R4kZxpJktjhIVObEnMwY/Fu0WUQKcaKyBAMSSgQXQaRPDx4EdCTc+fliusAylh7lXcBE7nbkfPsEENE52ALoKwxAMpYVBAH4BK5066KKtElEMmDBhwDKHMMgDJmMugQwkU4idzmD7MFEtc1I7owfyOg537ncsYAKHPR7AYmcpsyhwQrWzWILozdv7LHAChzncL8RJdApCj5AWxVJ7qgMF/RFVAzMQDKXOe2DIBE7pRm4Msi0QVF+YuugJqJr3TNlJqaCo1GgwMHDgi5/S4MgERuFc+ZwEQXFskAKHeqDIDTp0+HRqPBfffdV+u6Bx54ABqNBtOnT2/9wpqgSzifhETutMPCmcBEFxQVILoCaiZVBkAAaN++PZYtWwaL5Z9V/ysqKrB06VJ06NBBYGWN0yHEB0Yv1T6MRG633VwOSceZwET18tEDQd6iq6BmUm1yGDhwINq3b49Vq1Y5L1u1ahU6dOiAAQMGOC9bt24dLr30UgQFBSE0NBSTJk3CiRMnznvu+Ph4jB8/Hn5+fggPD8cdd9yBvLy8Fvk9dFoNxwESuVGlBFRxhiNR/dj9qwiqDYAAMHPmTCxevNj5/WeffYYZM2a4HFNWVobHHnsMe/bswYYNG6DVanHdddfB4ah7nFBRUREuu+wyDBgwAHv27MG6detw5swZTJ06tcV+jx4RbIoncqc8f84EJqoXA6AieF34EOW6/fbbMXfuXKSlpQEAtm/fjmXLlmHz5s3OY66//nqXn/nss88QFhaGo0ePonfv3rXO+d5772HAgAF4+eWXXX6mffv2SEpKQteuXd3+e3RvxycjkTulGLSIEl0EkadiAFQEVQfAsLAwTJw4EUuWLIEkSZg4cSLatGnjcszx48fxn//8B7t27UJeXp6z5S89Pb3OAHjw4EFs2rQJfn61u2VPnDjRIgGwJ1sAidzqsN2OS0UXQeSpGAAVQdUBEKjuBn7wwQcBAO+//36t6ydPnoyYmBgsWrQIkZGRcDgc6N27N6qq6p4pWFpaismTJ+PVV1+tdV1ERIR7i/8bu4CJ3GtneRVmiy6CyFMxACqC6gPgVVddhaqqKmg0Glx55ZUu1+Xn5yMxMRGLFi3CiBEjAADbtm077/kGDhyIlStXIjY2Fl5erXP3Bvsa0D7EhFMFlgsfTEQXtLPEAkmvhcbKNQGJXISaqmcBk+ypehIIAOh0Ohw7dgxHjx6FTue6sXVwcDBCQ0Px8ccfIzk5GRs3bsRjjz123vM98MADKCgowC233ILdu3fjxIkT+PXXXzFjxgzY7fYW+z0GdghusXMTqY1VAiq4JzBRbbFBoisgN1F9AASAgIAABATU7kbVarVYtmwZ9u7di969e+PRRx/F/Pnzz3uuyMhIbN++HXa7HVdccQX69OmDOXPmICgoCFpty93dg2IYAInciTOBieoQx/capdBIkiSJLoKaLz7TjEnvnr97moga7vOoEIw6ViC6DCLP8vgwoCNDoBKwBVAhurfzh49Bd+EDiahBDrXgkA0iWfLSAu056VApGAAVwkunRd/oQNFlECnGtrJK0SUQeZboAEDPhgalYABUEE4EIXKfv0oqILFVnegfnfgeoyQMgArCiSBE7iMBsHBPYKJ/dAoRXQG5EQOggrAFkMi9cvy43hmRU2cGQCVhAFSQYF8DOrbxFV0GkWKc8NKILoHIM4T7An5cGklJGAAV5uKOoaJLIFKMAzab6BKIPANb/xSHAVBhRnVtI7oEIsXYzpnARNV6homugNyMAVBhhnVuAy8tu62I3GFfaSUkI2cCk8ppNUB3Ni4oDQOgwgR469G/fZDoMogUo4wzgUnt4oIAEydEKQ0DoAKN6MKmeiJ3yfHlGx+pXA++pygRA6ACjeQ4QCK3Oa7jkApSOY7/UyQGQAXqFx2EIB+2WhC5wwE7ZwKTivnqgQ7cZlSJGAAVSKvVYHhntgISucMfpRWiSyASp0dY9SQQUhwGQIUaxXGARG5xpKwKkslLdBlEYvRgY4JSMQAq1MiuDIBE7lIawpnApFIc/6dYDIAK1S7QG72jAkSXQaQI2b5sASQVah8ABHqLroJaCAOggo3vHSG6BCJF4ExgUqUBfA9RMgZABZvYh09eInfYV8WZwKRCA/keomQMgAoW28YXPSLYDUzUXFtKLaJLIGpd0QFAW1/RVVALYgBUuIl92okugUj2jluscHBHEFITtv4pHgOgwk1gNzCRW5QEczA8qQgDoOIxACpcxzA/dG/nL7oMItnLYgsgqQW7f1WBAVAFOBuYqPmStJLoEohaxwAOHVIDBkAVmNiXT2ai5tpbyZnApBLs/lUFBkAV6NzWH13D/USXQSRrmzgTmNQgyh/g+4UqMACqxPUDo0WXQCRr6RU22P0NossgallDokRXQK2EAVAlpgyMhpeWuxkQNUdJEGcCk4JpNcAlbCxQCwZAlQjzN2JM97aiyyCStUwf7glMCta7LRBgFF0FtRIGQBW5aXB70SUQyVoiZwKTkg3je4SaMACqyJjubdHWn5/uiJpqd6VVdAlELSPQWN0CSKrBAKgiOq0G1w/i+A6iptpczJnApFCXRFePASTVYABUmansBiZqsqwqO+yBbEUnhdGA3b8qxACoMnFtfHFRbIjoMohky8yZwKQ0nUOAMG79pjYMgCo0dQg/6RE1VYa3TnQJRO7F1j9VYgBUoYl9IhBo4sb2RE1xTMOZwKQgJi9u/aZSDIAqZDLocMtFHUSXQSRLnAlMijK8A6Bnq7YaMQCq1LRhMdwZhKgJthSXQ+JTh5RAqwHGxIquggRhAFSpiEATJvRhsz9RY+VaHbAHciIIKcDACCDYJLoKEoQBUMXuHhEnugQiWSoK4lIwpADjOoqugARiAFSxvtFBGBIbLLoMItk5ZeSYKZK5ziFAh0DRVZBADIAqd9elbAUkaqyjnAlMcncZX/vVjgFQ5a7o2Q4dQnxEl0EkK39VVIkugajpwnyAvuGiqyDBGABVTqvVYPqwWNFlEMnKZs4EJjkbE8d9f4kBkKp3Bgnw9hJdBpFsmG0SbJw9SXLkoweGRouugjwAAyDBz+iFGcM5HoSoMQoDDaJLIGq8UTGAkR/4iQGQ/nbXiDi2AhI1QjpnApPcmLyAsVz6haoxABIAIMBbj7su5QsDUUPFSw7RJRA1zmVx1V3ARGAApLPMvDQWgSa+OBA1xC7OBCY58dFz6RdywQBITv7eeq4LSNRAfxRbIHEmJcnF2DiAH/DpLAyA5GLGcLYCEjVEmV2CNYQzgUkGfPXVS78QnYUBkFz4e+txD/cIJmqQggDOBCYZGNsR4CQ/OgcDINUyfXgcgjhQmOiC0gx8CSUP52cARseKroI8EF+9qBY/oxfuGcEZwUQXwpnA5PHGsfWP6sYASHWaOTwO7QK8RZdB5NF2WDgTmDxYgLF64WeiOjAAUp1MBh2euLKb6DKIPNqO4nJIOs4EJg91dTfu+kH1YgCkek0ZGIW+0YGiyyDyWBYHUMWZwOSJ2gcAl3DPX6ofAyDVS6PR4LlJPUWXQeTR8jgTmDzRDT0BrlNJ58EASOc1JDYE43u3E10GkcdK1fNllDzMgHZAl1DRVZCH4ysXXdDc8T1g8OKfClFdDjvsoksg+oeXFriuh+gqSAb4rk4X1CHUBzOGxYoug8gj7SjnTGDyIGNigTY+oqsgGWAApAZ58LLOCPXlWCeic+0ssUBiCzl5ggAjcFVn0VWQTPBVixrE31uPRy/vKroMIo9jlYCKUM4EJg8wqSvAvdypgRgAqcFuvagD+rcPEl0GkcfJ82frOAnWPgAY1l50FSQjDIDUYFqtBq9M6QMvLi1A5OKkns8JEkirAW7ry2VfqFEYAKlRekQE4G7uE0zk4pCdM4FJoMvigA5ctJ8ahwGQGm3OuC7oEMJZZkQ1tpVVii6B1CrUVD32j6iRGACp0bz1Orx0XW/RZRB5jL9KKiAZdKLLIDW6tQ/Avz1qAgZAapIRXcJwbf9I0WUQeQQJgCXEW3QZpDYXRQE9wkRXQTLFAEhN9tykngjy4ZIDRACQw5nA1Jr8DNX7/RI1EQMgNVmonxFPT+CWQ0QAcNKLMzCpFV3fozoEEjURAyA1y9TB7XFp5zaiyyAS7oDNJroEUosebYCLo0VXQTLHAEjN9vqN/RDI1edJ5TgTmFqFt1f1xA+iZmIApGZrF+jNWcGkevtKKyEZORuTWtjUXkAol+Gi5mMAJLeY1DcS1w2IEl0GkVDl3BOYWtKAdsAl7Pol92AAJLf57zW9EBXEN0BSrzO+HApBLSTQCNzCrl9yHwZAcht/bz3enNqP21GSaiVzJjC1BA2AO/px1i+5FQMgudXFHUMxa2Qn0WUQCbGfM4GpJYyJA3pywWdyLwZAcrvHLu+KXpEBossganVbSytEl0BKEx0AXNtddBWkQAyA5HYGLy3evrk/vPX88yJ1iS+rgmTyEl0GKYVBB8wcAHjxtZTcj39V1CI6t/XHS9dywDKpT2kIJ0KRm9zYE2jnJ7oKUigGQGox1w+Kxq0XdxBdBlGryvZlCyC5wdBoYDhfP6nlMABSi3p+ck/0iw4UXQZRqzmu40xgaqYOgcDNXFyfWhYDILUoo5cOH9w+CME+XB+N1GGflTOBqRl89cA9AwE9d5WhlsUASC0uKsiEt28ewPUBSRX+KLGILoHkSoPqSR/c6o1aAQMgtYqRXcMwZ1xX0WUQtbgkixUO7ghCTTG5G9CD6/1R62AApFbz0GWdcVn3tqLLIGpxpcHeoksguekbDlzJRfSp9TAAUqvRaDR4a2p/dAhh9wYp22kfzgSmRmjrC0zrB2g4ToZaDwMgtapAHz0+nTYY/t58gyTlSuL4fWooow6YNQgwcdgAtS4GQGp1XcL98eFtg+DFWSGkUHurOBOYGkCrAe4eCET6i66EVIgBkIS4tEsb/O9arnNFyrSFM4GpIW7uDfTiuGgSgwGQhLn5og64bxQHPZPypFbYYPc3iC6DPNnlHYFLudMHicMASEL9+6pumNgnQnQZRG5XwpnAVJ+BEcC13UVXQSrHAEhCaTQavDG1HwZ0CBJdCpFbnTZxohPVoVMwZ/ySR2AAJOG89TosunMw2oeYRJdC5DYJGkl0CeRp2voC9w7mNm/kERgAySO08TNi8fQhCORSCKQQezgTmM7mZwDuH1L9L5EHYAAkj9G5rT8+n3kRfA38dEzyt6m4XHQJ5CkMOuDeQdUtgEQeggGQPEr/9kH4ZNoQGL34p0nyllVlhz3AKLoMEs1LC9w3GOgUIroSIhd8lyWPM7RTKD66fRD0Og6SJnkzcyawuuk0wD0Dge5tRFdCVAsDIHmkMd3bYsFNA6DjbiEkY5neHM6gWloNMGMA0CdcdCVEdWIAJI81sW8EXpnSh6slkGwd40xgddIAuL1v9Xp/RB6KAZA82tTB7fHcxJ6iyyBqkr8qraJLIBFu6g1cEi26CqLzYgAkjzfz0jg8dnlX0WUQNdqW4nJIbMFWlyk9gJExoqsguiAGQJKFh8d2wZxxXUSXQdQouVYH7IGcCKIak7oC4zqKroKoQRgASTbmjOuKpydw/0ySl6IgLgWjCpO7AhP4IZXkgwGQZGXWyE548ZpenBhCsnGKM4GVTQPgxp7AeIY/khcGQJKdO4bG4rXr+3KJGJKFYxJnAiuWVlM923dMnOhKiBqNAZBk6cbB7bHgpv7wYggkD7erskp0CdQSdBpg5gBgaHvRlRA1iUaS+PGU5Ov3o2fwwNJ9qLI5RJdCVKdALw0OFErgkoAKotcCswYBvdqKroSoydgCSLJ2ec9wfHLnYHjr+adMnslsk2DjlnDK4e0FPHARwx/JHt81SfZGdg3D13dfjGAfvehSiOpUGMiZwIrgqwcevhjoGiq6EqJmYwAkRRgUE4JV9w9HbKiP6FKIakk3ciaw7IWagMeGArFBoishcgsGQFKMuDa+WHX/cAyKCRZdCpGLo+AYVVmLCwKeHA5E+IuuhMhtGABJUUJ8Dfj67osxsQ83YSfPsdPCmcCyNTACmHMJ4M9ufFIWzgImRZIkCf+3NgEL/zgpuhQi+Oo0iDcDGgdfbmXlik7ANd3AledJiRgASdG+/DMNL/x4BHa+8ZJgSQYTDHkW0WVQQ+g0wM29geEdRFdC1GLYBUyKdsclMfjkzsHwNXAQPolVwC5EeTD9vcwLwx8pHAMgKd6Y7m2x+oHh6NjGV3QppGJpRr7cerxQE/D4MKB7G9GVELU4viKRKnQN98cPDw7H5T3DRZdCKhUvcSawR+vdFpg7gjN9STUYAEk1/L31+PiOQXjiym7gFsLU2naWV4ougeqiATCpKzB7MMDF5ElFOAmEVOmPpFw8smw/CsutokshlTBpgaMlGmjsfMn1GL56YMYAoGeY6EqIWh0DIKnWqYJyzP56L+Izi0WXQiqRaPSBMbdcdBkEADGBwD2DgBCT6EqIhGAXMKlW+xAffHffMNw4KFp0KaQSef4G0SUQAIzoAPxrGMMfqRoDIKmat16H+Tf2wytT+sCk51Ix1LJSDXzJFUqvBe7sB9zSB/DiY0HqxmcAEYBbLuqAnx4ajh4RAaJLIQU77OBMYGGiA4B/XwpcwhZ/IoBjAIlcVNrseHVtIhbvSAGfGeRuowJM+DyDu4G0Kg2AcR2Byd3Y6kd0FgZAojpsSszBk98dQm4Jl+4g99FrgKQyLTQ2tgS2ihATMK0f0CVUdCVEHocBkKgeBWVVeHrVYaw7ki26FFKQBJMvvM+UiS5D+S6KAm7qBZi4th9RXRgAiS7gu70ZmPfjEZRU2kSXQgqwNSwY7U8Uii5DuXz11ZM8BkaIroTIo3FABNEF3DAoGmvnjMCILtwflJrvpIHb0LSY7m2AZ0Yy/BE1AAMgUQNEB/vgy7suxptT+yHEl2u5UdMdsttFl6A8Ji/g1j7AQxcBQd6iqyGSBXYBEzVSQVkVXvz5KFbvzxRdCsnQ0ABvfJNRIboM5egXDtzcGwhk8CNqDAZAoib6IykXz3x/GKcKuKwHNZwOQHKFDpoqtgQ2S6ARuKk30L+d6EqIZIkBkKgZLFV2vPl7Ij7bngq7g08lapijPn7wyS4VXYY8aTXAyBhgclfO8CVqBgZAIjeIzzTjqVWHEJ9ZLLoUkoEtbYMRk8yZwI0WE1g9w7dDoOhKiGSPAZDITewOCct3n8Kbvycir7RKdDnkwT6LDMFlCQWiy5APXz0wqSswIqa6BZCImo0BkMjNSiqseG9TMhZvT0UVd3ygOjwSHoBHj7O1+IK8tMCoGGB8F8CH3b1E7sQASNRC0vPL8craY1gbz51EyNVAPyNWneY2g+c1oB1wbXcgzFd0JUSKxABI1MJ2nczHi2uOcnwgOWkAnKzUQVPJmcC1xAQC1/cEOoeIroRI0RgAiVqBwyHhu30ZeP3XROSUsOWHgCN+fvA9zZnATsHewNXdqvfw1XCcH1FLYwAkakXlVTZ8viMNH/9xAoXlVtHlkEAbw4PR8ThnAsPkBYzrCIztCBh0oqshUg0GQCIByiptWLIjFYu2nkQRg6AqfRwZgivUPBPYRw9cFgeMieV6fkQCMAASCVRaacPibSn4ZFsKzBYGQTWZHR6Af6txJjCDH5FHYAAk8gDFFVZ8ti0Fn25LQUmFTXQ51Ar6+BrxU5aKxoP66IGxccDoWAY/Ig/AAEjkQcwWKz7dehKf70xji6AKpFi9oLEoPPD7/t3ix+BH5FEYAIk8UHmVDSv2ZGDx9hSk5peLLodayGF/f/hnloguo2WEmqpD3/AOgLeX6GqI6BwMgEQezOGQ8PuxM/h0awr+SlXxhAGF+r1dCLokKexx7RRc3eLXrx23bSPyYAyARDJxKKMIn2xNwS+Hs2Bz8GmrBB9GhmC8EmYC6zTAwIjq4BcTJLoaImoABkAimckyW7Bkeyq++SsdxZwwImt3tw3As8kyngnsqwcu7QCMigWCvEVXQ0SNwABIJFMVVjvWxWdj2e507EopAJ/J8tPVZMBvZ6pEl9F4HYOBodHAkCgu3kwkUwyARAqQll+G5btPYeW+DJwpVtHSIgpw0qaHVg6LgQcagYujq4NfuJ/oaoiomRgAiRTE7pCwKSEHy/ecwqaEHI4VlIFDAf4IyPDQmcA6DdAnvDr09WrLSR1ECsIASKRQOSUVWLUvEz8cOI1jWTIeZ6Zwv7YLRrckD9sTONIfGNYeGBIJ+BtFV0NELYABkEgFUvLKsObQaaw5nM0w6GHejQzBZE+YCRzhBwyIAAa0A6ICRFdDRC2MAZBIZVLyyvDL4Sz8fCiLYdADTAvzx7wTgrqA2wcA/dtVL+HCcX1EqsIASKRiNWFwbXwWjpwu5kxiAWK9vbA5p5WW89Ggep2+Ae2qW/va+LTO7RKRx2EAJCIA1WMGtyblYUtSLrYl56GgTIbLk8jUSYcB2tIWur999EC3UKBHGNAzDAgxtcztEJGsMAASUS0Oh4TDmWZsScrFH0m52H+qCHbOKG4xBwIDEHTKTd3xWg0QF1Qd+Hq0qW7x4+xdIjoHAyARXZDZYsWO5DxsTc7D3tRCJOWUsLvYjX6JCEHPxGZMBGnrWx32urcBurUBvL3cVxwRKRIDIBE1mtlixf70QuxLK8SetEIcPFWEsiq76LJk683IEExp6Exgow7oEAjEBVfvyBEXxKVaiKjRGACJqNnsDgnHsoqxN60Qe9MKsf9UITIKLWwlbKBb2/jj5ZP1zARu61sd8uL+DntRAezSJaJmYwAkohZRWmlDYnYJErNLkJBdjIS//2+2yGDbs1YWYdBhp1kCIvyBKP/qhZijAoDoAMDPILo8IlIgBkAialVZZgsSskuQkFWC42dKcKqwHKcKLDhTUqGKFsMgHz1iQ33Rua1f9VdY9b+xIT5s2SOiVsMASEQeocrmQGaRBacKynGqsBwZhTX/tyCz0ILC8iqPn4nspdUgPMAbUUEmRAZ5IyrYhMig6q/ov//1NXKCBhGJxwBIRLIgSRLMFisKyqpQWF6FgjIrCsuqUFBehYKy6q+i8iqUV9lRZXOg0ub4+99zv3egyu4AAOi0GnhpNdDrtPDSaeCl1UKv08BLp4FeW32Z0UuHQJMegT56BJr0CDLpEfT3/wNNBuf/g30MCPM3QsdWPCKSAQZAIlIdSZIgSYCWYY2IVIoBkIiIiEhltKILICIiIqLWxQBIREREpDIMgEREREQqwwBIREREpDIMgEREREQqwwBIREREpDIMgEREREQqwwBIREREpDIMgEREREQqwwBIREREpDIMgEREREQqwwBIREREpDIMgEREREQqwwBIREREpDIMgEREREQqwwBIREREpDIMgEREREQqwwBIREREpDIMgEREREQqwwBIREREpDIMgEREREQqwwBIREREpDIMgEREREQqwwBIREREpDIMgEREREQqwwBIREREpDIMgEREREQqwwBIREREpDIMgEREREQq8/+cfejbQh6GzgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top Pros:\n",
      "    Pros  Mentions\n",
      "favorite        15\n",
      "  smooth        10\n",
      "    nice         7\n",
      "   yummy         5\n",
      "   light         4\n",
      "\n",
      "Top Cons:\n",
      "     Cons  Mentions\n",
      "     weak         7\n",
      "   bitter         5\n",
      " horrible         3\n",
      "defective         2\n",
      " terrible         2\n",
      "\n",
      "Summary of Reviews:\n",
      "good coffee brews hot\n"
     ]
    }
   ],
   "source": [
    "productId = \"B003VXFK44\" # Set the product ID you want to analyze\n",
    "\n",
    "loaded_model = joblib.load('gender_predictor.pkl')\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "pros = {}\n",
    "cons = {}\n",
    "\n",
    "def analyze_review(review, rating):    \n",
    "    # Extract adjectives (possible pros/cons)\n",
    "    doc = nlp(review)\n",
    "    excluded_words = ['good', 'bad', 'great', 'amazing', 'wonderful', 'best', 'many']\n",
    "    aspects = [token.text.lower() for token in doc if token.pos_ == 'ADJ' and token.text.lower() not in excluded_words]\n",
    "\n",
    "    # Positive Review\n",
    "    if rating >= 4:\n",
    "        for aspect in aspects:\n",
    "            pros[aspect] = pros.get(aspect, 0) + 1\n",
    "    # Negative review\n",
    "    elif rating <= 2:\n",
    "        for aspect in aspects:\n",
    "            cons[aspect] = cons.get(aspect, 0) + 1\n",
    "    \n",
    "    return\n",
    "\n",
    "def predict_gender(name):\n",
    "    predicted_gender = loaded_model.predict([name.lower()])\n",
    "    if predicted_gender[0] == 0:\n",
    "        return('Male')\n",
    "    else:\n",
    "        return('Female')\n",
    "\n",
    "# Extract Pros/Cons and Gender from each matching productId\n",
    "df.loc[df['ProductId'] == productId, 'Extracted Aspects'] = df[df['ProductId'] == productId].apply(lambda row: analyze_review(row['Summary'], row['Score']), axis=1)\n",
    "df.loc[df['ProductId'] == productId, 'Gender'] = df[df['ProductId'] == productId].apply(lambda row: predict_gender(row['ProfileName']), axis=1)\n",
    "\n",
    "# Calculate gender proportion\n",
    "num_reviews = len(df[(df['ProductId'] == productId)])\n",
    "num_males = len(df[(df['ProductId'] == productId) & (df['Gender'] == 'Male')])\n",
    "male_proportion = num_males / num_reviews\n",
    "\n",
    "# Create DataFrames for Pros and Cons for visualization\n",
    "top_pros = dict(sorted(pros.items(), key=lambda item: item[1], reverse=True)[:5])  # Top 5 Pros\n",
    "top_cons = dict(sorted(cons.items(), key=lambda item: item[1], reverse=True)[:5])  # Top 5 Cons\n",
    "pros_df = pd.DataFrame(list(top_pros.items()), columns=['Pros', 'Mentions'])\n",
    "cons_df = pd.DataFrame(list(top_cons.items()), columns=['Cons', 'Mentions'])\n",
    "\n",
    "# Output results\n",
    "if male_proportion < 0.4:\n",
    "    print('This product is most popular among females.')\n",
    "elif male_proportion < 0.6:\n",
    "    print('This product is popular among both males and females.')\n",
    "else:\n",
    "    print('This product is most popular among males')\n",
    "\n",
    "# Pie chart data\n",
    "labels = ['Male', 'Female']\n",
    "sizes = [num_males, num_reviews-num_males]\n",
    "colors = ['#1f77b4', '#ff69b4']  # Blue for Male, Orange for Female\n",
    "\n",
    "# Plotting the pie chart\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', startangle=100)\n",
    "plt.title('Gender Distribution for Product ID {}'.format(productId))\n",
    "plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "plt.show()\n",
    "\n",
    "print('\\nTop Pros:')\n",
    "print(pros_df.to_string(index=False))\n",
    "\n",
    "print('\\nTop Cons:')\n",
    "print(cons_df.to_string(index=False))\n",
    "\n",
    "print('\\nSummary of Reviews:')\n",
    "print(summarize_product_reviews(productId, df, net, src_vocab, tgt_vocab, max_len_text, device))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
